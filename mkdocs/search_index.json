{
    "docs": [
        {
            "location": "/", 
            "text": "Polgraw all-sky pipeline: search for almost monochromatic gravitational wave signals\n\n\nThis is the documentation of a gravitational-wave search pipeline of the \nPolgraw\n group. \n\n\nThe pipeline's source code is \navailable here\n. \n\n\nPipeline flowchart\n\n\n\n\n\n\n\n\n\n\nTopics\n\n\n\n\nInput data generation\n \n\n\nF-statistic candidate signal search\n\n\nCoincidences between candidates\n\n\nFalse alarm probability of coincidences\n \n\n\nFollowup of interesting outliers\n\n\nSensitivity upper limits\n\n\nPipeline: a minimal example\n\n\nDocuments and publications\n\n\n\n\nContributors\n\n\nIn alphabetic order:\n\n\n\n\nPia Astone \n\n\nMicha\u0142 Bejger\n\n\nJan Bolek\n\n\nPawe\u0142 Cieciel\u0105g\n\n\nOrest Dorosh\n\n\nAleksander Garus\n\n\nAndrzej Kr\u00f3lak\n\n\nM\u00e1t\u00e9 Ferenc Nagy-Egri\n\n\nMaciej Pi\u0119tka\n\n\nAndrzej Pisarski \n\n\nGevorg Poghosyan\n\n\nMagdalena Sieniawska \n\n\nRafa\u0142 Skrzypiec", 
            "title": "Home"
        }, 
        {
            "location": "/#polgraw-all-sky-pipeline-search-for-almost-monochromatic-gravitational-wave-signals", 
            "text": "This is the documentation of a gravitational-wave search pipeline of the  Polgraw  group.   The pipeline's source code is  available here .", 
            "title": "Polgraw all-sky pipeline: search for almost monochromatic gravitational wave signals"
        }, 
        {
            "location": "/#pipeline-flowchart", 
            "text": "", 
            "title": "Pipeline flowchart"
        }, 
        {
            "location": "/#topics", 
            "text": "Input data generation    F-statistic candidate signal search  Coincidences between candidates  False alarm probability of coincidences    Followup of interesting outliers  Sensitivity upper limits  Pipeline: a minimal example  Documents and publications", 
            "title": "Topics"
        }, 
        {
            "location": "/#contributors", 
            "text": "In alphabetic order:   Pia Astone   Micha\u0142 Bejger  Jan Bolek  Pawe\u0142 Cieciel\u0105g  Orest Dorosh  Aleksander Garus  Andrzej Kr\u00f3lak  M\u00e1t\u00e9 Ferenc Nagy-Egri  Maciej Pi\u0119tka  Andrzej Pisarski   Gevorg Poghosyan  Magdalena Sieniawska   Rafa\u0142 Skrzypiec", 
            "title": "Contributors"
        }, 
        {
            "location": "/input_data/", 
            "text": "Input data generation\n\n\nExtract narrow-band time series from Short Fourier Transform databases with \nextract_band\n\n\nThis program converts Short Fourier Transformation series to time series. \nWritten by Pia Astone (INFN, Physics Department of University of Rome \"La Sapienza\").\n\n\nPrerequisites\n\n\nC compiler \n standard C libraries (\nmath.h\n). Links to the PSS library (created by Pia Astone).\n\n\nExample\n\n\n% extract_band \n input_file\n\n\n\n\n\n\nwhere \ninput_file\n is an ASCII file containing the following rows:  \n\n\n\n\nMaximal number of SFT\n\n\nThe name of the output file\n\n\nThe list of SFT files\n\n\nThe frequency band in Hz\n\n\nThe width of frequency band in Hz\n\n\n\n\ne.g.,  \n\n\n100000\nJ0034+1612_2010-10-10.out\nJ0034+1612_2010-10-10.list\n718.2480\n1\n\n\n\n\n\nOutput\n\n\n% Beginning freq- Band- Samples in one stretch- Subsampling factor- inter (overlapping, 2 if data were overlapped)- Frequency step- Scaling factor- ***The data are real and imag of the FFT\n\n\n% 908.152344 0.250000 256 8192.000000 2  0.0009766 1.000000e-20\n\n\n% FFT number in the file; Beginning mjd days; Gps s; Gps ns;\n\n\n% 100 55099.5879745370 937922816 0\n\n \n4.59662571e+02\n  \n2.27630825e+01\n\n\n-\n3.50387007e+02\n \n-\n2.20005558e+02\n\n \n3.57587904e+02\n  \n1.01217077e+02\n\n \n1.74400486e+02\n  \n2.62086552e+02\n\n \n2.21804800e+02\n \n-\n5.20278366e+02\n\n\n-\n3.87826732e+02\n \n-\n1.55758978e+02\n\n\n\n\n\n\ngen2day\n description\n\n\nTODO\n For the implementation see \nhere\n. \n\n\nInput data structure\n\n\nThe time series input data is divided into time segments of typically a few days length and consists - for each detector - of the input time series data, the ephemerides and the grid-generating matrix file (defining the parameter space of the search). \n\n\nA single run requires 2 data files for each detector \nDD\n, stored in \ndata_dir/nnn/DD\n subdirectory, where \nDD\n is currently either \nH1\n (Hanford), \nL1\n (Livingston) or \nV1\n (Virgo Cascina):\n\n\n\n\nxdat_nnn_bbbb.bin\n - time-domain narrow-band data sequence, sampled at  half second. \nnnn\n is the number of time frame, \nbbbb\n is the number of frequency band (see below),\n\n\nDetSSB.bin\n  -  location  of  the  detector  w.r.t. the Solar\n   System Barycenter (SSB), in Cartesian coordinates, sampled at \ndt\n sampling rate (array of size \n2N\n), \n\n\nLast two records in this file  are the angle \nphir\n, determining the  position of Earth in  its diurnal motion, and the obliquity of  the ecliptic \nepsm\n, both calculated for the first sample of the data. \n\n\n\n\nThird file is the sky positions-frequency-spindown grid file in linear coordinates (common for all the detectors), stored in \ndata_dir/nnn\n in case of the network search (one grid file is used by all the detectors) or in each detector directory separately (in case of single-detector searches): \n\n\n\n\ngrid.bin\n - generator matrix of an optimal grid of templates (defining the parameter space; see \nhere\n for details).  \n\n\n\n\nAn example for two LIGO detectors H1 and L1, and data frame segments \nnnn=001-008\n with pure Gaussian noise 2-day time segments with sampling time equal to 2s for a fiducial narrow band number \nbbbb=1234\n (\nxdatc_nnn_1234.bin\n) coresponding the the band frequency \nfpo=308.859375\n is \navailable here\n. \n\n\nA typical directory structure is as follows: \n\n\n001\n\u251c\u2500\u2500 grid.bin\n\u251c\u2500\u2500 H1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 DetSSB.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 grid.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 starting_date\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 xdatc_001_1234.bin\n\u2514\u2500\u2500 L1\n    \u251c\u2500\u2500 DetSSB.bin\n    \u251c\u2500\u2500 grid.bin\n    \u251c\u2500\u2500 starting_date\n    \u2514\u2500\u2500 xdatc_001_1234.bin\n\n\n\n\n\nBeginning of each time frame is saved in the \nnnn/DD/starting_date\n file, e.g., \n\n\n% cat 2d_0.25/001/H1/starting_date\n\n\n1.1260846080e+09\n\n\n\n\n\n\nFrames \nnnn\n are labelled with three-digit consecutive number. For the \nO1\n data, the bandwidth is \n0.25 Hz\n (\ndt = 2s\n). For a given \ndt\n, the reference band frequency \nfpo\n is defined as \n\n\nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}. \n\n\nNeighboring bands overlap by \n2^{-5}/(2dt)\\ \\mathrm{Hz}\n. \nO1\n data in the frequency range \n10-2000\\ \\mathrm{Hz}\n contains \n8220\n narrow \n0.25 Hz\n bands. With the \ndt = 2s\n sampling time, the total number of data points in time segments of 2 sideral day long is \nN=86164\n. For lower frequencies (\n10-475 Hz\n, see \ndocuments and publications\n) 6 day length segments are used (\nN=258492\n double-precision numbers).\n\n\nGaussian input data (for tests)\n\n\nThe directory \nsearch/network/src-cpu\n contains a standalone \ngauss-xdat\n code to generate time series drawn from the Gaussian distribution. \n\n\nPrerequisites\n\n\nC compiler and standard libraries (\nmath.h\n, \nsys/time.h\n for \ngettimeofday\n). The code depends on the \nGNU Scientific Library (GSL)\n random number generation (\ngsl/gsl_rng.h\n) and random number distributions (\ngsl/gsl_randist.h\n; using the Marsaglia-Tsang ziggurat implementation).\n\n\nCompilation\n\n\n% gcc gauss-xdat.c -o gauss-xdat -lm -lgsl -lgslcblas\n\n\n\n\n\nExample\n\n\nThe program takes input values from the command line: \n\n\n% ./gauss-xdat N amplitude sigma output-file \n\n\n\n\n\ne.g., \n\n\n% ./gauss-xdat \n86164\n \n1\n \n1\n ../../../testdata/2d_0.25/001/H1/xdatc_001_1234.bin\n\n\n\n\n\nThe output is a binary file containing \nN\n double-precision numbers.", 
            "title": "Input data generation"
        }, 
        {
            "location": "/input_data/#input-data-generation", 
            "text": "", 
            "title": "Input data generation"
        }, 
        {
            "location": "/input_data/#extract-narrow-band-time-series-from-short-fourier-transform-databases-with-extract_band", 
            "text": "This program converts Short Fourier Transformation series to time series. \nWritten by Pia Astone (INFN, Physics Department of University of Rome \"La Sapienza\").", 
            "title": "Extract narrow-band time series from Short Fourier Transform databases with extract_band"
        }, 
        {
            "location": "/input_data/#prerequisites", 
            "text": "C compiler   standard C libraries ( math.h ). Links to the PSS library (created by Pia Astone).", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/input_data/#example", 
            "text": "% extract_band   input_file   where  input_file  is an ASCII file containing the following rows:     Maximal number of SFT  The name of the output file  The list of SFT files  The frequency band in Hz  The width of frequency band in Hz   e.g.,    100000\nJ0034+1612_2010-10-10.out\nJ0034+1612_2010-10-10.list\n718.2480\n1", 
            "title": "Example"
        }, 
        {
            "location": "/input_data/#output", 
            "text": "% Beginning freq- Band- Samples in one stretch- Subsampling factor- inter (overlapping, 2 if data were overlapped)- Frequency step- Scaling factor- ***The data are real and imag of the FFT  % 908.152344 0.250000 256 8192.000000 2  0.0009766 1.000000e-20  % FFT number in the file; Beginning mjd days; Gps s; Gps ns;  % 100 55099.5879745370 937922816 0 \n  4.59662571e+02    2.27630825e+01  - 3.50387007e+02   - 2.20005558e+02 \n  3.57587904e+02    1.01217077e+02 \n  1.74400486e+02    2.62086552e+02 \n  2.21804800e+02   - 5.20278366e+02  - 3.87826732e+02   - 1.55758978e+02", 
            "title": "Output"
        }, 
        {
            "location": "/input_data/#gen2day-description", 
            "text": "TODO  For the implementation see  here .", 
            "title": "gen2day description"
        }, 
        {
            "location": "/input_data/#input-data-structure", 
            "text": "The time series input data is divided into time segments of typically a few days length and consists - for each detector - of the input time series data, the ephemerides and the grid-generating matrix file (defining the parameter space of the search).   A single run requires 2 data files for each detector  DD , stored in  data_dir/nnn/DD  subdirectory, where  DD  is currently either  H1  (Hanford),  L1  (Livingston) or  V1  (Virgo Cascina):   xdat_nnn_bbbb.bin  - time-domain narrow-band data sequence, sampled at  half second.  nnn  is the number of time frame,  bbbb  is the number of frequency band (see below),  DetSSB.bin   -  location  of  the  detector  w.r.t. the Solar\n   System Barycenter (SSB), in Cartesian coordinates, sampled at  dt  sampling rate (array of size  2N ),   Last two records in this file  are the angle  phir , determining the  position of Earth in  its diurnal motion, and the obliquity of  the ecliptic  epsm , both calculated for the first sample of the data.    Third file is the sky positions-frequency-spindown grid file in linear coordinates (common for all the detectors), stored in  data_dir/nnn  in case of the network search (one grid file is used by all the detectors) or in each detector directory separately (in case of single-detector searches):    grid.bin  - generator matrix of an optimal grid of templates (defining the parameter space; see  here  for details).     An example for two LIGO detectors H1 and L1, and data frame segments  nnn=001-008  with pure Gaussian noise 2-day time segments with sampling time equal to 2s for a fiducial narrow band number  bbbb=1234  ( xdatc_nnn_1234.bin ) coresponding the the band frequency  fpo=308.859375  is  available here .   A typical directory structure is as follows:   001\n\u251c\u2500\u2500 grid.bin\n\u251c\u2500\u2500 H1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 DetSSB.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 grid.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 starting_date\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 xdatc_001_1234.bin\n\u2514\u2500\u2500 L1\n    \u251c\u2500\u2500 DetSSB.bin\n    \u251c\u2500\u2500 grid.bin\n    \u251c\u2500\u2500 starting_date\n    \u2514\u2500\u2500 xdatc_001_1234.bin  Beginning of each time frame is saved in the  nnn/DD/starting_date  file, e.g.,   % cat 2d_0.25/001/H1/starting_date  1.1260846080e+09   Frames  nnn  are labelled with three-digit consecutive number. For the  O1  data, the bandwidth is  0.25 Hz  ( dt = 2s ). For a given  dt , the reference band frequency  fpo  is defined as  \nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}.  \nNeighboring bands overlap by  2^{-5}/(2dt)\\ \\mathrm{Hz} .  O1  data in the frequency range  10-2000\\ \\mathrm{Hz}  contains  8220  narrow  0.25 Hz  bands. With the  dt = 2s  sampling time, the total number of data points in time segments of 2 sideral day long is  N=86164 . For lower frequencies ( 10-475 Hz , see  documents and publications ) 6 day length segments are used ( N=258492  double-precision numbers).", 
            "title": "Input data structure"
        }, 
        {
            "location": "/input_data/#gaussian-input-data-for-tests", 
            "text": "The directory  search/network/src-cpu  contains a standalone  gauss-xdat  code to generate time series drawn from the Gaussian distribution.", 
            "title": "Gaussian input data (for tests)"
        }, 
        {
            "location": "/input_data/#prerequisites_1", 
            "text": "C compiler and standard libraries ( math.h ,  sys/time.h  for  gettimeofday ). The code depends on the  GNU Scientific Library (GSL)  random number generation ( gsl/gsl_rng.h ) and random number distributions ( gsl/gsl_randist.h ; using the Marsaglia-Tsang ziggurat implementation).", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/input_data/#compilation", 
            "text": "% gcc gauss-xdat.c -o gauss-xdat -lm -lgsl -lgslcblas", 
            "title": "Compilation"
        }, 
        {
            "location": "/input_data/#example_1", 
            "text": "The program takes input values from the command line:   % ./gauss-xdat N amplitude sigma output-file   e.g.,   % ./gauss-xdat  86164   1   1  ../../../testdata/2d_0.25/001/H1/xdatc_001_1234.bin  The output is a binary file containing  N  double-precision numbers.", 
            "title": "Example"
        }, 
        {
            "location": "/grid_generation/", 
            "text": "Grid generation\n\n\nImplementation of optimal grid of templates\n\n\nThe implementation of the \nbanks of templates for all-sky narrow-band searches of gravitational waves from spinning neutron stars\n paper can be found \nhere\n.\n\n\nPrerequisites\n\n\nC++ compiler.\n\n\nExample\n\n\nUsing the \ntest Gaussian data\n:  \n\n\n% ./gridgen -m 0.5 -p dfg -d ../testdata/2d_0.25/001/H1/ -n 17 \n\n\n\n\n\n\nwhere   \n\n\n\n\n-m\n is the minimal-match parameter\n\n\n-d\n is the directory with the ephemerids data \n\n\n-n\n is the \n\\log_2\n of the number of data points \n\n\n-p\n denotes the full output (density of covering, Fisher and grid matrices)\n\n\n\n\nThe output is \n\n\ngrid.bin will be saved in ../testdata/2d_0.25/001/H1/grid.bin\nCovariance, Density of covering\nDensity of covering: 0.25 1.76768559133\nfftpad: 1\nNormalized grid matrix:\n4.793689962143e-05      0.000000000000e+00      0.000000000000e+00      0.000000000000e+00\n-1.742438091399e-04     2.161320668089e-09      0.000000000000e+00      0.000000000000e+00\n-2.479053689156e-02     -1.684378936606e-09     2.558634258126e+02      0.000000000000e+00\n9.606645586405e-03      3.102095432504e-09      -1.321384079961e+02     1.941709922254e+02\n\nFisher matrix:\n8.333333333333e-02      8.333333333333e-02      8.125315899793e-06      1.296986289673e-06\n8.333333333333e-02      8.888888888889e-02      8.127119310149e-06      1.288789877048e-06\n8.125315899793e-06      8.127119310149e-06      7.922523031349e-10      1.264584758632e-10\n1.296986289673e-06      1.288789877048e-06      1.264584758632e-10      2.020158195389e-11\n\nGrid matrix:\n4.130435018981e+00      0.000000000000e+00      0.000000000000e+00      0.000000000000e+00\n-1.501354357073e+01     1.604615232547e+01      0.000000000000e+00      0.000000000000e+00\n-2.136051820725e+03     -1.250522487924e+01     2.204621622171e+07      0.000000000000e+00\n8.277470103070e+02      2.303068516072e+01      -1.138557378658e+07     1.673054937411e+07\n\n\n\n\n\nFull description of options\n\n\nDESCRIPTION\n         GridsGenerator \n(\nGG\n)\n is designated to be used in all-sky narrow-band\n         searches of continuous gravitational waves. Program allow to:\n         - generate efficient grid\n(\ns\n)\n \nfor\n chosen initial \ntime\n of observation \n(\n1\n)\n.\n         - generate reduced Fisher matrix \nfor\n chosen initial \ntime\n of observation \n(\n1\n)\n,\n         - generate density of covering \n(\n2\n)\n.\n         \n(\n1\n)\n To get result, ephemeris must be provided.\n         \n(\n2\n)\n Result can be get without ephemeris \n(\nfor\n more information see flags: -nd\n         \n(\n--ndata\n))\n.\n\nFLAGS\n   Flags with \n(\noptional\n)\n argument\n(\ns\n)\n:\n         -c or --covariance \nmin\n \nmax\n \nstep\n\n                 Covariance. Flag -c is required \n(\neven without argument\n)\n to get result.\n                 \nmin\n - minimum value of covariance but not less than 0\n;\n\n                 default set: 0.75.\n                 \nmax\n - optional maximum value of covariance but less than 1.\n                 \nstep\n - optional step value of covariance\n;\n\n                 default set: 0.01.\n\n                 \n# Calculation are preform only in two cases:\n\n                 \n# 1. No flag are provided. Sets are read from file \ngg.ini\n.\n\n                 \n# Result(s) is(are) printed to file(s) - see configuration file: \ngg.ini\n.\n\n                 \n# 2. Flag -c (--covariance) or -m (--match) is used.\n\n                 \n# Result(s) is(are) printed to tty.\n\n\n         -m or --match \nmin\n \nmax\n \nstep\n\n                 Minimal match \n(\nMM^2 \n==\n covariance\n)\n.\n                 \nmin\n - minimum value of minimal match but not less than 0\n;\n\n                 default set: MM^2 \n=\n 0.75.\n                 \nmax\n - optional maximum value of minimal match but less than 1.\n                 \nstep\n - optional step value of minimal match\n;\n\n                 default set: 0.1.\n                 \n## If flags -c (--covariance) and -m (--match) provided simultaneously,\n\n                 \n## program will read options from -c flag only.\n\n\n\n         -d or --directory \npath\n\n                 Directory containing ephemeris \n(\nneed to contain binary files:\n                 \nrSSB.bin\n, \nrDet.bin\n, \nrDetSSB.bin\n)\n.\n                 \npath\n - take path to directory.\n                 E.g. -d 001: directory \n001\n located inside folder with GridsGenerator.\n                 If directory is not provided, program will try to find ephemeris\n                 in directory with GridsGenerator.\n\n         -i or --initial \nmin\n \nmax\n \nstep\n\n                 Initial \ntime\n of observation.\n                 \nmin\n - minimum value of initial time\n;\n\n                 default set: 0.5.\n                 \nmax\n - optional maximum value of initial time.\n                 \nstep\n - optional step value of minimal match\n;\n\n                 \nif\n not provided step will be \nset\n on \nstep\n \n=\n max - min.\n\n\n         -a or --algorithm \ntype\n\n                 Algorithm \ntype\n to choose.\n                 \ntype\n take option: s1, s2, a. Algorithms:\n                 s1 - based on fully analytic formula,\n                 s2 - partially numeric formula.\n                 Accuracy \nfor\n algorithm \ns2\n depended on -na \n(\n--nalpha\n)\n and -nr \n(\n--nradius\n)\n\n                 flags.\n                 a - automatically choose algorithm \ns1\n or \ns2\n. Use this argument to allow\n                 GridsGenerator to decide which algorithm \n(\nfor\n given parameters\n)\n should be\n                 used to get grid with better density of covering.\n                 Information about implemented algorithms can be found in article:\n                 http://dx.doi.org/10.1088/0264-9381/32/14/145014\n                 Default set: a.\n\n         -n or --nfft \nint\n\n                 Number of Fourier bins.\n                 \nint\n take positive integer number without zero \n(\nexponent\n)\n.\n                 E.g. to get grid destined to work with discreet\n                 Fourier transform \n(\nDFT, FFT\n)\n with length \n1024\n put same exponent of 2: 10\n                 \n(\n1024\n \n==\n 2^10\n)\n.\n                 Default set: \n20\n \n(\n1048576\n \n=\n 2^20\n)\n.\n\n         -nd or --ndata \nint\n\n                 Number of data \n(\ndata length collected by detector, equal to length\n                 of ephemeris\n)\n.\n                 \nint\n take positive integer number including zero.\n                 If \nint\n is \nset\n to zero data length will be \nread\n from ephemeris*.\n                 If \nint\n is bigger than zero program will able to obtain density of\n                 covering only**.\n                 Default set: 0.\n                 * With this \nset\n \n(\n-nd \n0\n or -ndata 0\n)\n density is obtained without using\n                 information stored in file \ndataS2.txt\n.\n                 \n### With this set density of covering for algorithm \ns2\n is always\n\n                 \n### obtaining with maximal accuracy, depending only from flags: -na, -nr.\n\n                 \n### Density of covering for algorithm \ns1\n is always obtained with maximal\n\n                 \n### accuracy regardless to sets of -nd flag.\n\n                 ** Ephemeris are not used and because of that grid\n(\ns\n)\n and reduced Fisher\n                 matrix cannot be obtained. Density of covering \nfor\n algorithm \ns2\n will be\n                 be obtained in approximated way based on information*** collected \n(\nin \n                 \ndataS2.txt\n file\n)\n during previous runs with ephemeris. File \ndataS2.txt\n\n                 collect information about coverings only \nfor\n algorithm \ns2\n.\n                 Program inform which algorithm has been used only when work without\n                 ephemeris \n(\nint\n bigger that zero\n)\n.\n                 E.g. \n(\nwithout ephemeris\n)\n -nd 344656:\n                 Covariance, Density, Algorithm\n                 0.86      1.82      s2\n                 0.87      1.8494      s1\n                 0.88      1.77685      s1\n                 E.g. \n(\ndata length taken from ephemeris\n)\n -nd 0:\n                 Covariance, Density of covering\n                 0.86 1.82299890516\n                 0.87 1.84940429814\n                 0.88 1.77685017541\n                 *** Information stored in file \ndataS2.txt\n are independent of ephemeris.\n                 Based on this information density of covering can be obtained fast but\n                 in approximated way \n(\ngenerally speaking more collected data allows\n                 to get more accurate results\n)\n.\n\n         -na or --nalpha \nint\n\n                 Number of loops \n(\nincrementation deep\n)\n in root finding algorithm.\n                 \nint\n take positive integer number without zero.\n                 This flag affect only on \ns2\n algorithm.\n                 Default set: 35.\n\n         -nr or --nradius \nint\n\n                 Number of loops in covering radius \n(\ndeep hole\n)\n finding algorithm.\n                 \nint\n take positive integer number without zero.\n                 This flag affect only on \ns2\n algorithm.\n                 Default set: 20.\n\n         -cv or --convert \nbool\n\n                 Convert grid from space with hyper-sphere to hyper-ellipsoid space.\n                 \nbool\n take argument: t \n(\ntrue\n)\n, f \n(\nfalse\n)\n.\n                 Default set: t.\n\n         -ch or --chop \nbool\n\n                 Chop result to zero \nif\n value of result is smaller than \n|\n10^-12\n|\n.\n                 \nbool\n take argument: t \n(\ntrue\n)\n, f \n(\nfalse\n)\n.\n                 Default set: f.\n\n         -p or --print \nstring\n\n                 Print result\n(\ns\n)\n.\n                 \nstring\n take argument\n(\ns\n)\n: d, f, g.\n                 d - density of covering,\n                 f - Fisher reduced matrix,\n                 g - grid.\n                 Option can be joined \n(\norder is not important\n)\n, e.g. df, dg, fg, dfg.\n                 Default set: g.\n                 \n#### If argument of flag -nd is set to be bigger than zero, flag -p\n\n                 \n#### can accept only \nd\n argument.\n\n\n   Flags with no arguments:\n         -h or --help\n                 Display this help.\n\n         -ht or --helptxt\n                 Print this \nhelp\n to text file.\n\n         -v or --version\n                 Display information about version of GridsGenerator.\n\n         -aa or --author\n                 About author\n(\ns\n)\n. Display information about developer\n(\ns\n)\n.", 
            "title": "Grid generation"
        }, 
        {
            "location": "/grid_generation/#grid-generation", 
            "text": "", 
            "title": "Grid generation"
        }, 
        {
            "location": "/grid_generation/#implementation-of-optimal-grid-of-templates", 
            "text": "The implementation of the  banks of templates for all-sky narrow-band searches of gravitational waves from spinning neutron stars  paper can be found  here .", 
            "title": "Implementation of optimal grid of templates"
        }, 
        {
            "location": "/grid_generation/#prerequisites", 
            "text": "C++ compiler.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/grid_generation/#example", 
            "text": "Using the  test Gaussian data :    % ./gridgen -m 0.5 -p dfg -d ../testdata/2d_0.25/001/H1/ -n 17    where      -m  is the minimal-match parameter  -d  is the directory with the ephemerids data   -n  is the  \\log_2  of the number of data points   -p  denotes the full output (density of covering, Fisher and grid matrices)   The output is   grid.bin will be saved in ../testdata/2d_0.25/001/H1/grid.bin\nCovariance, Density of covering\nDensity of covering: 0.25 1.76768559133\nfftpad: 1\nNormalized grid matrix:\n4.793689962143e-05      0.000000000000e+00      0.000000000000e+00      0.000000000000e+00\n-1.742438091399e-04     2.161320668089e-09      0.000000000000e+00      0.000000000000e+00\n-2.479053689156e-02     -1.684378936606e-09     2.558634258126e+02      0.000000000000e+00\n9.606645586405e-03      3.102095432504e-09      -1.321384079961e+02     1.941709922254e+02\n\nFisher matrix:\n8.333333333333e-02      8.333333333333e-02      8.125315899793e-06      1.296986289673e-06\n8.333333333333e-02      8.888888888889e-02      8.127119310149e-06      1.288789877048e-06\n8.125315899793e-06      8.127119310149e-06      7.922523031349e-10      1.264584758632e-10\n1.296986289673e-06      1.288789877048e-06      1.264584758632e-10      2.020158195389e-11\n\nGrid matrix:\n4.130435018981e+00      0.000000000000e+00      0.000000000000e+00      0.000000000000e+00\n-1.501354357073e+01     1.604615232547e+01      0.000000000000e+00      0.000000000000e+00\n-2.136051820725e+03     -1.250522487924e+01     2.204621622171e+07      0.000000000000e+00\n8.277470103070e+02      2.303068516072e+01      -1.138557378658e+07     1.673054937411e+07", 
            "title": "Example"
        }, 
        {
            "location": "/grid_generation/#full-description-of-options", 
            "text": "DESCRIPTION\n         GridsGenerator  ( GG )  is designated to be used in all-sky narrow-band\n         searches of continuous gravitational waves. Program allow to:\n         - generate efficient grid ( s )   for  chosen initial  time  of observation  ( 1 ) .\n         - generate reduced Fisher matrix  for  chosen initial  time  of observation  ( 1 ) ,\n         - generate density of covering  ( 2 ) .\n          ( 1 )  To get result, ephemeris must be provided.\n          ( 2 )  Result can be get without ephemeris  ( for  more information see flags: -nd\n          ( --ndata )) .\n\nFLAGS\n   Flags with  ( optional )  argument ( s ) :\n         -c or --covariance  min   max   step \n                 Covariance. Flag -c is required  ( even without argument )  to get result.\n                  min  - minimum value of covariance but not less than 0 ; \n                 default set: 0.75.\n                  max  - optional maximum value of covariance but less than 1.\n                  step  - optional step value of covariance ; \n                 default set: 0.01.\n\n                  # Calculation are preform only in two cases: \n                  # 1. No flag are provided. Sets are read from file  gg.ini . \n                  # Result(s) is(are) printed to file(s) - see configuration file:  gg.ini . \n                  # 2. Flag -c (--covariance) or -m (--match) is used. \n                  # Result(s) is(are) printed to tty. \n\n         -m or --match  min   max   step \n                 Minimal match  ( MM^2  ==  covariance ) .\n                  min  - minimum value of minimal match but not less than 0 ; \n                 default set: MM^2  =  0.75.\n                  max  - optional maximum value of minimal match but less than 1.\n                  step  - optional step value of minimal match ; \n                 default set: 0.1.\n                  ## If flags -c (--covariance) and -m (--match) provided simultaneously, \n                  ## program will read options from -c flag only. \n\n\n         -d or --directory  path \n                 Directory containing ephemeris  ( need to contain binary files:\n                  rSSB.bin ,  rDet.bin ,  rDetSSB.bin ) .\n                  path  - take path to directory.\n                 E.g. -d 001: directory  001  located inside folder with GridsGenerator.\n                 If directory is not provided, program will try to find ephemeris\n                 in directory with GridsGenerator.\n\n         -i or --initial  min   max   step \n                 Initial  time  of observation.\n                  min  - minimum value of initial time ; \n                 default set: 0.5.\n                  max  - optional maximum value of initial time.\n                  step  - optional step value of minimal match ; \n                  if  not provided step will be  set  on  step   =  max - min.\n\n\n         -a or --algorithm  type \n                 Algorithm  type  to choose.\n                  type  take option: s1, s2, a. Algorithms:\n                 s1 - based on fully analytic formula,\n                 s2 - partially numeric formula.\n                 Accuracy  for  algorithm  s2  depended on -na  ( --nalpha )  and -nr  ( --nradius ) \n                 flags.\n                 a - automatically choose algorithm  s1  or  s2 . Use this argument to allow\n                 GridsGenerator to decide which algorithm  ( for  given parameters )  should be\n                 used to get grid with better density of covering.\n                 Information about implemented algorithms can be found in article:\n                 http://dx.doi.org/10.1088/0264-9381/32/14/145014\n                 Default set: a.\n\n         -n or --nfft  int \n                 Number of Fourier bins.\n                  int  take positive integer number without zero  ( exponent ) .\n                 E.g. to get grid destined to work with discreet\n                 Fourier transform  ( DFT, FFT )  with length  1024  put same exponent of 2: 10\n                  ( 1024   ==  2^10 ) .\n                 Default set:  20   ( 1048576   =  2^20 ) .\n\n         -nd or --ndata  int \n                 Number of data  ( data length collected by detector, equal to length\n                 of ephemeris ) .\n                  int  take positive integer number including zero.\n                 If  int  is  set  to zero data length will be  read  from ephemeris*.\n                 If  int  is bigger than zero program will able to obtain density of\n                 covering only**.\n                 Default set: 0.\n                 * With this  set   ( -nd  0  or -ndata 0 )  density is obtained without using\n                 information stored in file  dataS2.txt .\n                  ### With this set density of covering for algorithm  s2  is always \n                  ### obtaining with maximal accuracy, depending only from flags: -na, -nr. \n                  ### Density of covering for algorithm  s1  is always obtained with maximal \n                  ### accuracy regardless to sets of -nd flag. \n                 ** Ephemeris are not used and because of that grid ( s )  and reduced Fisher\n                 matrix cannot be obtained. Density of covering  for  algorithm  s2  will be\n                 be obtained in approximated way based on information*** collected  ( in \n                  dataS2.txt  file )  during previous runs with ephemeris. File  dataS2.txt \n                 collect information about coverings only  for  algorithm  s2 .\n                 Program inform which algorithm has been used only when work without\n                 ephemeris  ( int  bigger that zero ) .\n                 E.g.  ( without ephemeris )  -nd 344656:\n                 Covariance, Density, Algorithm\n                 0.86      1.82      s2\n                 0.87      1.8494      s1\n                 0.88      1.77685      s1\n                 E.g.  ( data length taken from ephemeris )  -nd 0:\n                 Covariance, Density of covering\n                 0.86 1.82299890516\n                 0.87 1.84940429814\n                 0.88 1.77685017541\n                 *** Information stored in file  dataS2.txt  are independent of ephemeris.\n                 Based on this information density of covering can be obtained fast but\n                 in approximated way  ( generally speaking more collected data allows\n                 to get more accurate results ) .\n\n         -na or --nalpha  int \n                 Number of loops  ( incrementation deep )  in root finding algorithm.\n                  int  take positive integer number without zero.\n                 This flag affect only on  s2  algorithm.\n                 Default set: 35.\n\n         -nr or --nradius  int \n                 Number of loops in covering radius  ( deep hole )  finding algorithm.\n                  int  take positive integer number without zero.\n                 This flag affect only on  s2  algorithm.\n                 Default set: 20.\n\n         -cv or --convert  bool \n                 Convert grid from space with hyper-sphere to hyper-ellipsoid space.\n                  bool  take argument: t  ( true ) , f  ( false ) .\n                 Default set: t.\n\n         -ch or --chop  bool \n                 Chop result to zero  if  value of result is smaller than  | 10^-12 | .\n                  bool  take argument: t  ( true ) , f  ( false ) .\n                 Default set: f.\n\n         -p or --print  string \n                 Print result ( s ) .\n                  string  take argument ( s ) : d, f, g.\n                 d - density of covering,\n                 f - Fisher reduced matrix,\n                 g - grid.\n                 Option can be joined  ( order is not important ) , e.g. df, dg, fg, dfg.\n                 Default set: g.\n                  #### If argument of flag -nd is set to be bigger than zero, flag -p \n                  #### can accept only  d  argument. \n\n   Flags with no arguments:\n         -h or --help\n                 Display this help.\n\n         -ht or --helptxt\n                 Print this  help  to text file.\n\n         -v or --version\n                 Display information about version of GridsGenerator.\n\n         -aa or --author\n                 About author ( s ) . Display information about developer ( s ) .", 
            "title": "Full description of options"
        }, 
        {
            "location": "/search_for_candidates/", 
            "text": "F-statistic candidate signal search\n\n\nProduction serial code for a network of detectors is available at \nhere\n. \nOpenMP\n version is at \nthis location\n. To get the whole pipeline, run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n. \n\n\nAlgorithm flowchart\n\n\n\n\n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n. \nGNU Scientific Library (GSL)\n and the \nFFTW library\n (version 3.0 or later) are needed to run the code. \nGNU struct dirent\n objects are used to read the directories. \n\n\nOptionally, \nSLEEF\n or \nYEPPP!\n, libraries for high-performance computing that are optimized for speed are used to evaluate the trigonometric functions in the search code. These libraries are ported with the source code and are located in \nsrc/lib\n. The choice which of these libraries to use has to be made at compilation time by modifying the \nMakefile\n. \n\n\nCompilation\n\n\nRun  \nmake gwsearch-cpu\n or \nmake\n in \nsearch/network/src-cpu\n, resulting  binary is called \ngwsearch-cpu\n (this is the default \nC\n version not-optimized with \nopenMP\n; for the \nopenMP\n version see the \nsearch/network/src-openmp\n directory). Modify the \nMakefile\n to fit your system. By default the \nYEPPP!\n library is selected. \n\n\n\n\nFull list of switches\n\n\nFor the full list of options, type\n\n\n% ./gwsearch-cpu --help \n\n\n\n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-data\n\n\nData directory (default is \n.\n)\n\n\n\n\n\n\n-output\n\n\nOutput directory (default is \n./candidates\n)\n\n\n\n\n\n\n-ident\n\n\nFrame number\n\n\n\n\n\n\n-band\n\n\nBand number\n\n\n\n\n\n\n-label\n\n\nCustom label for the input and output files\n\n\n\n\n\n\n-range\n\n\nUse file with grid range or pulsar position\n\n\n\n\n\n\n-getrange\n\n\nWrite grid ranges \n save fft wisdom \n exit (ignore -r)\n\n\n\n\n\n\n-cwd\n\n\nChange to directory \ndir\n\n\n\n\n\n\n-threshold\n\n\nThreshold for the \n\\mathcal{F}\n-statistic (default is \n20\n)\n\n\n\n\n\n\n-hemisphere\n\n\nHemisphere (default is 0 - does both)\n\n\n\n\n\n\n-fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-usedet\n\n\nUse only detectors from string (default is \nuse all available\n)\n\n\n\n\n\n\n-addsig\n\n\nAdd signal with parameters from \nfile\n\n\n\n\n\n\n-narrowdown\n\n\nNarrow-down the frequency band (range \n[0, 0.5] +- around center\n)\n\n\n\n\n\n\n\n\nAlso: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--whitenoise\n\n\nWhite Gaussian noise assumed\n\n\n\n\n\n\n--nospindown\n\n\nSpindowns neglected\n\n\n\n\n\n\n--nocheckpoint\n\n\nState file will not be created (no checkpointing)\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\nExample\n\n\nMinimal call to \ngwsearch-cpu\n is as follows (code compiled with the \nGNUSINCOS\n option): \n\n\n% ./gwsearch-cpu -data ../../../testdata/2d_0.25 -dt 2 -output . -ident 001 -band 1234 -nod 2  \n\n\n\n\n\n\nwhere\n\n\n\n\ndata\n directory is the base directory of input data files,\n\n\nSampling time \ndt\n is \n2 s\n, \n\n\noutput\n directory is a directory to write the output (e.g., in current directory, . ) \n\n\nident\n is the number of time frame to be analyzed (\n001\n),\n\n\nnod\n number of days is \n2\n, \n\n\nband\n is the number of the frequency band (see the \ninput data structure\n for details). \n\n\n\n\n\n\nNetwork of detectors\n\n\nTest data frames \nnnn=001-008\n with pure Gaussian noise 2-day time segments with sampling time equal to 2s (\nxdatc_nnn_1234.bin\n) for two LIGO detectors H1 and L1 are \navailable here\n. \n\n\nA sample call is \n\n\n% \nLD_LIBRARY_PATH\n=\nlib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu \n\\\n\n  -data ../../../testdata/2d_0.25/ \n\\\n\n  -ident \n001\n \n\\\n\n  -band \n1234\n \n\\\n\n  -dt \n2\n \n\\ \n\n  -nod \n2\n \n\\ \n\n  -addsig sig1 \n\\ \n \n  -output . \n\\\n\n  -threshold 14.5 \n\\\n\n  --nocheckpoint\n\n\n\n\n\nwhere the \nLD_LIBRARY_PATH\n points to the location of the \nYEPPP!\n library. \n\n\nThe program will proceed assuming that \n\n\n\n\nthe data directory for frame \n001\n is located at \n../../../testdata/2d_0.25/001\n and contain subdirectories with input data for H1, L1 and/or V1 detectors (all available detectors are used by default; to select specific detectors, use \n-usedet\n option), \n\n\nthe grid of parameters files is expected to be in \n../../../testdata/2d_0.25/001\n, \n\n\nband\n equals to \n1234\n,  \n\n\nthe sampling time \ndt\n equals \n2 s\n, \n\n\nnumber of days \nnod\n in \n2\n, \n\n\nthe \n-addsig\n option is used to add a software injection to pure noise Gaussian data. The signal's parameters are randomly generated using the \nsigen\n code (for more details see the \nminimal example\n).  \n\n\nthe threshold for the \n\\mathcal{F}\n-statistic is set to be \n14.5\n,\n\n\n-output\n is the current directory, \n\n\n--nocheckpoint\n disables the checkpointing (writing the last visited position on the grid to the \nstate\n file), \n\n\n\n\nOutput files\n\n\nBinary output files, containing trigger candidate events above an arbitrary threshold (option \n-threshold\n for the \n\\mathcal{F}\n-statistic, default 20), are written to the \noutput_dir\n directory. There are two output files for every input data sequence: \ntriggers_nnn_bbbb_1.bin\n and\n\ntriggers_nnn_bbbb_2.bin\n,  where  \n1\n and  \n2\n correspond to the northern and southern ecliptic hemisphere. Each trigger (candidate) event occupies \n40\n consecutive bytes (5 double numbers), with the following meaning:\n\n\n\n\n\n\n\n\nRecord no.\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\nfrequency [radians, between 0 and \n\\pi\n] above \nfpo\n\n\n\n\n\n\n2\n\n\nspindown [\n\\mathrm{Hz/s}\n]\n\n\n\n\n\n\n3\n\n\ndeclination [radians, between \n\\pi\n and \n-\\pi\n]\n\n\n\n\n\n\n4\n\n\nright ascension [radians, between 0 and \n2\\pi\n]\n\n\n\n\n\n\n5\n\n\nsignal-to-noise ratio\n\n\n\n\n\n\n\n\nFor the example above, the first 10 triggers from \ntriggers_001_1234_2.bin\n are \n\n\n3.05617018e+00 -3.42376198e-08 -7.68007347e-02 2.59248668e+00 5.06667333e+00 \n1.18243015e+00 -3.20762991e-08 -7.68007347e-02 2.59248668e+00 5.05528873e+00 \n1.08103361e-01 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.07085254e+00 \n1.90022435e+00 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.15191593e+00 \n1.90000217e+00 -2.55923371e-08 -7.68007347e-02 2.59248668e+00 5.42638039e+00 \n2.09224664e+00 -2.34310165e-08 -7.68007347e-02 2.59248668e+00 5.20879551e+00 \n2.38731576e+00 -2.12696958e-08 -7.68007347e-02 2.59248668e+00 5.31983396e+00 \n3.00543165e+00 -1.91083751e-08 -7.68007347e-02 2.59248668e+00 5.29454616e+00 \n7.49333983e-01 -1.26244131e-08 -7.68007347e-02 2.59248668e+00 5.08724856e+00 \n2.08710778e-01  3.43510887e-10 -7.68007347e-02 2.59248668e+00 5.17537018e+00 \n\n\n\n\n\n\n\nAuxiliary output files\n\n\n\n\n\n\nwisdom-hostname.dat\n - performance-testing file created by the \nFFTW\n. The \nhostname\n variable is determined by a call to \ngethostname()\n, \n\n\n\n\n\n\nstate_nnn_bbbb.dat\n - checkpointing file containing the last grid point visited. The search can  be safely restarted, calculations will continue  from the last grid position saved to this file. After successful termination, checkpoint file is left empty.", 
            "title": "F-statistic candidate signal search"
        }, 
        {
            "location": "/search_for_candidates/#f-statistic-candidate-signal-search", 
            "text": "Production serial code for a network of detectors is available at  here .  OpenMP  version is at  this location . To get the whole pipeline, run  git clone https://github.com/mbejger/polgraw-allsky.git .", 
            "title": "F-statistic candidate signal search"
        }, 
        {
            "location": "/search_for_candidates/#algorithm-flowchart", 
            "text": "", 
            "title": "Algorithm flowchart"
        }, 
        {
            "location": "/search_for_candidates/#prerequisites", 
            "text": "The code is written in standard  C .  GNU Scientific Library (GSL)  and the  FFTW library  (version 3.0 or later) are needed to run the code.  GNU struct dirent  objects are used to read the directories.   Optionally,  SLEEF  or  YEPPP! , libraries for high-performance computing that are optimized for speed are used to evaluate the trigonometric functions in the search code. These libraries are ported with the source code and are located in  src/lib . The choice which of these libraries to use has to be made at compilation time by modifying the  Makefile .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/search_for_candidates/#compilation", 
            "text": "Run   make gwsearch-cpu  or  make  in  search/network/src-cpu , resulting  binary is called  gwsearch-cpu  (this is the default  C  version not-optimized with  openMP ; for the  openMP  version see the  search/network/src-openmp  directory). Modify the  Makefile  to fit your system. By default the  YEPPP!  library is selected.", 
            "title": "Compilation"
        }, 
        {
            "location": "/search_for_candidates/#full-list-of-switches", 
            "text": "For the full list of options, type  % ./gwsearch-cpu --help      Switch  Description      -data  Data directory (default is  . )    -output  Output directory (default is  ./candidates )    -ident  Frame number    -band  Band number    -label  Custom label for the input and output files    -range  Use file with grid range or pulsar position    -getrange  Write grid ranges   save fft wisdom   exit (ignore -r)    -cwd  Change to directory  dir    -threshold  Threshold for the  \\mathcal{F} -statistic (default is  20 )    -hemisphere  Hemisphere (default is 0 - does both)    -fpo  Reference band frequency  fpo  value    -dt  Data sampling time dt (default value:  0.5 )    -usedet  Use only detectors from string (default is  use all available )    -addsig  Add signal with parameters from  file    -narrowdown  Narrow-down the frequency band (range  [0, 0.5] +- around center )     Also:            --whitenoise  White Gaussian noise assumed    --nospindown  Spindowns neglected    --nocheckpoint  State file will not be created (no checkpointing)    --help  This help", 
            "title": "Full list of switches"
        }, 
        {
            "location": "/search_for_candidates/#example", 
            "text": "Minimal call to  gwsearch-cpu  is as follows (code compiled with the  GNUSINCOS  option):   % ./gwsearch-cpu -data ../../../testdata/2d_0.25 -dt 2 -output . -ident 001 -band 1234 -nod 2     where   data  directory is the base directory of input data files,  Sampling time  dt  is  2 s ,   output  directory is a directory to write the output (e.g., in current directory, . )   ident  is the number of time frame to be analyzed ( 001 ),  nod  number of days is  2 ,   band  is the number of the frequency band (see the  input data structure  for details).", 
            "title": "Example"
        }, 
        {
            "location": "/search_for_candidates/#network-of-detectors", 
            "text": "Test data frames  nnn=001-008  with pure Gaussian noise 2-day time segments with sampling time equal to 2s ( xdatc_nnn_1234.bin ) for two LIGO detectors H1 and L1 are  available here .   A sample call is   %  LD_LIBRARY_PATH = lib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu  \\ \n  -data ../../../testdata/2d_0.25/  \\ \n  -ident  001   \\ \n  -band  1234   \\ \n  -dt  2   \\  \n  -nod  2   \\  \n  -addsig sig1  \\   \n  -output .  \\ \n  -threshold 14.5  \\ \n  --nocheckpoint  where the  LD_LIBRARY_PATH  points to the location of the  YEPPP!  library.   The program will proceed assuming that    the data directory for frame  001  is located at  ../../../testdata/2d_0.25/001  and contain subdirectories with input data for H1, L1 and/or V1 detectors (all available detectors are used by default; to select specific detectors, use  -usedet  option),   the grid of parameters files is expected to be in  ../../../testdata/2d_0.25/001 ,   band  equals to  1234 ,    the sampling time  dt  equals  2 s ,   number of days  nod  in  2 ,   the  -addsig  option is used to add a software injection to pure noise Gaussian data. The signal's parameters are randomly generated using the  sigen  code (for more details see the  minimal example ).    the threshold for the  \\mathcal{F} -statistic is set to be  14.5 ,  -output  is the current directory,   --nocheckpoint  disables the checkpointing (writing the last visited position on the grid to the  state  file),", 
            "title": "Network of detectors"
        }, 
        {
            "location": "/search_for_candidates/#output-files", 
            "text": "Binary output files, containing trigger candidate events above an arbitrary threshold (option  -threshold  for the  \\mathcal{F} -statistic, default 20), are written to the  output_dir  directory. There are two output files for every input data sequence:  triggers_nnn_bbbb_1.bin  and triggers_nnn_bbbb_2.bin ,  where   1  and   2  correspond to the northern and southern ecliptic hemisphere. Each trigger (candidate) event occupies  40  consecutive bytes (5 double numbers), with the following meaning:     Record no.       1  frequency [radians, between 0 and  \\pi ] above  fpo    2  spindown [ \\mathrm{Hz/s} ]    3  declination [radians, between  \\pi  and  -\\pi ]    4  right ascension [radians, between 0 and  2\\pi ]    5  signal-to-noise ratio     For the example above, the first 10 triggers from  triggers_001_1234_2.bin  are   3.05617018e+00 -3.42376198e-08 -7.68007347e-02 2.59248668e+00 5.06667333e+00 \n1.18243015e+00 -3.20762991e-08 -7.68007347e-02 2.59248668e+00 5.05528873e+00 \n1.08103361e-01 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.07085254e+00 \n1.90022435e+00 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.15191593e+00 \n1.90000217e+00 -2.55923371e-08 -7.68007347e-02 2.59248668e+00 5.42638039e+00 \n2.09224664e+00 -2.34310165e-08 -7.68007347e-02 2.59248668e+00 5.20879551e+00 \n2.38731576e+00 -2.12696958e-08 -7.68007347e-02 2.59248668e+00 5.31983396e+00 \n3.00543165e+00 -1.91083751e-08 -7.68007347e-02 2.59248668e+00 5.29454616e+00 \n7.49333983e-01 -1.26244131e-08 -7.68007347e-02 2.59248668e+00 5.08724856e+00 \n2.08710778e-01  3.43510887e-10 -7.68007347e-02 2.59248668e+00 5.17537018e+00", 
            "title": "Output files"
        }, 
        {
            "location": "/search_for_candidates/#auxiliary-output-files", 
            "text": "wisdom-hostname.dat  - performance-testing file created by the  FFTW . The  hostname  variable is determined by a call to  gethostname() ,     state_nnn_bbbb.dat  - checkpointing file containing the last grid point visited. The search can  be safely restarted, calculations will continue  from the last grid position saved to this file. After successful termination, checkpoint file is left empty.", 
            "title": "Auxiliary output files"
        }, 
        {
            "location": "/coincidences/", 
            "text": "Coincidences between candidates\n\n\nIn order to establish the probability of detection of a real gravitational wave, after finding the candidate signals with the \nF-statistic candidate signal search\n, the pipeline searches for coincidences between candidates found in different time frames. \n\n\nThe coincidences code is available at \ngithub\n. To get it, run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n.\n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n. The only dependency is \nGNU Scientific Library (GSL)\n, used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues). \nGNU struct dirent\n objects are used to read the directories. \n\n\nThe idea behind coincidences\n\n\nAfter finding the candidate signals in different time frames (\nsearch\n), we want to confirm the existence of signals with the same parameters along the span of time segments. to further perform a validation search for high-coincidence, or otherwise interesting candidates (the \nfollowup\n, currently under construction). To do this, the candidates from a list of trigger files (time frames) are read, and for each trigger file\n\n\n\n\na candidate is transformed to a well-defined time moment (frequency shifted to a reference frame), \n\n\ntranslated into linear (integer) coordinates, \n\n\nduplicates within each frame are removed, \n\n\nlist of unique candidates from all the frames is created and sorted, \n\n\nduplicates are counted - these are the coincidences. \n\n\n\n\nTODO: describe cell shifts (16 different shifts in total: 0101, 0110, 0010 etc. in f, s, d, a directions) and scaling of cells (used to define the linear parameters for a given cell to subsequently compare the candidate values)\n \n\n\nCompilation\n\n\nRun \nmake coincidences\n; resulting binary is called \ncoincidences\n. Modify the \nMakefile\n to fit your system.\n\n\nFull list of switches\n\n\nType \n\n\n% ./coincidences --help \n\n\n\n\n\n\nto obtain the following description: \n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-data\n\n\nData directory (default is \n./candidates\n)\n\n\n\n\n\n\n-output\n\n\nOutput directory (default is \n./coinc-results\n)\n\n\n\n\n\n\n-shift\n\n\nCell shifts in \nfsda\n directions (4 digit number, e.g. \n0101\n, default \n0000\n)\n\n\n\n\n\n\n-scale\n\n\nCell scaling in \nfsda\n directions (4 digit number, e.g. \n4824\n, default \n1111\n)\n\n\n\n\n\n\n-refr\n\n\nReference frame number\n\n\n\n\n\n\n-fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-trigname\n\n\nPart of triggers' name (for identifying files)\n\n\n\n\n\n\n-refloc\n\n\nLocation of the reference grid.bin and starting_date files\n\n\n\n\n\n\n-mincoin\n\n\nMinimal number of coincidences recorded\n\n\n\n\n\n\n-narrowdown\n\n\nNarrow-down the frequency band (range [0, 0.5] +- around center)\n\n\n\n\n\n\n-snrcutoff\n\n\nSignal-to-noise threshold cutoff (default value: 6)\n\n\n\n\n\n\n\n\nAlso:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\nExample\n\n\nUsing the software injection added to 2-day Gaussian noise data segments (see \nminimal example of the pipeline\n):\n\n\n% for s in {0..1}{0..1}{0..1}{0..1}; do ./coincidences -data ../../search/network/src-cpu -output . -shift $s -scale 4444 -refr 4 -dt 2 -trigname 1234_2 -refloc ../../testdata/2d_0.25/004 -nod 2 -fpo 308.859375 -snrcutoff 5; done 2\n summary\n\n\n\n\n\n\nThis assumes that for the band \nbbbb=1234\n and the sampling time \ndt=2\\ \\mathrm{s}\n the band frequency \nfpo=308.859375\\ \\mathrm{Hz}\n, because \n\n\nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}.\n\n\nThe reference grid file \ngrid.bin\n, corresponding to the reference frame \n004\n (\n-refr 4\n) is located at the \n-refloc\n location. Signal-to-noise ratio cutoff is set to 5 (\n-snrcutoff 5\n). Some output is directed to \nstdin\n. For example, the output for shift \n0000\n is \n\n\nNumber of days is 2\nThe SNR threshold cutoff is 5.000000000000, corresponding to F-statistic value of 14.500000000000\nReading the reference grid.bin at ../../testdata/2d_0.25/004\nfftpad from the grid file: 1\nSettings dt: 2.000000, oms: 3881.241374\nReference frame number: 4\nCell shifts  in f, s, d, a directions: 0 0 0 0 \nCell scaling in f, s, d, a directions: 4 4 4 4 \nReading triggers... Frame 5: 1966/2040\nReading triggers... Frame 1: 2409/2483\nReading triggers... Frame 4: 2176/2384\nReading triggers... Frame 3: 2132/2247\nReading triggers... Frame 8: 2372/2408\nReading triggers... Frame 2: 2197/2249\nReading triggers... Frame 6: 2225/2305\nReading triggers... Frame 7: 2175/2226\nTotal number of candidates from all frames: 17652\n\n\n\n\n\nThe highest multiplicity coincidence for each shift is streamed to the \nsummary\n file via the \nstderr\n (\n2\n summary\n). From this list of 16 lines, the highest multiplicity coincidence with the highest signal-to-noise is selected (\nsort -gk5 -gk10 summary | tail -1\n):\n\n\n1234_2 1111 308.859375     8     5  9.95663703e-01 -1.10830358e-09 -1.12585347e-01 1.97463002e+00 1.246469e+01 5 2040 1987 1 2483 2419 4 2384 2193 3 2247 2137 8 2408 2363 2 2249 2172 6 2305 2220 7 2226 2191 6 2 8 3 5\n\n\n\n\n\nThis output contains the \n\n\n\n\nband_hemisphere\n identifier (\n1234\\_2\n), \n\n\nthe \nshift\n value (\n1111\n), \n\n\nthe \nfpo\n reference band frequency (\n308.859375\\ \\mathrm{Hz}\n), \n\n\nthe number of triggers files read (\n8\n), \n\n\nthe multiplicity of coincidence found (\nN_{coin}=5\n), \n\n\narithmetic mean values of the frequency \n\\bar{f}\n (range \n[0:2\\pi]\n, corresponding to the width of the band), mean frequency derivative \n\\bar{s}\n (spindown, in \nHz/s\n), equatorial coordinate system sky positions \n\\bar{\\delta}\n (\n[\\pi:-\\pi]\n) and \n\\bar{\\alpha}\n (\n[0:2\\pi]\n), and the mean signal-to-noise ratio, \n\\widetilde{\\mathrm{snr}}=\\sqrt{\\sum_i \\mathrm{snr}_i^2}\n (\n5\n floating-point numbers), \n\n\n8 triplets of the frame number, number of all candidates in the corresponding triggers file, and the number of unique candidates after sorting to unique cells (\n8\\times 3\n integers), \n\n\nframe numbers participating in the coincidence (\n5\n integers). \n\n\n\n\nCoincidences larger or equal \nmincoin\n (default value \n3\n) are recorded in binary files \n.coi\n, separately for each shift, in the \n-output\n directory. Each coincidence is a set of following numbers: \n\n\nN_{coin},\\quad\\bar{f},\\quad\\bar{s},\\quad\\bar{\\delta},\\quad\\bar{\\alpha},\\quad\\widetilde{\\mathrm{snr}},\\quad\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}},\\quad\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}}\n\n\nwhere \n\n\n\n\n\n\nN_{coin}\n is the multiplicity of coincidence (written as one \nunsigned short int\n), \n\n\n\n\n\\bar{f}\n, \n\\bar{s}\n, \n\\bar{\\delta}\n, \n\\bar{\\alpha}\n and \n\\widetilde{\\mathrm{snr}}\n are the mean parameters of the signal (\n5\\times\n\n\nfloat\n),\n\n\n\n\n\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}}\n are the frame numbers (\nN_{coin}\\times\n\n\nunsigned short int\n), \n\n\n\n\n\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}}\n are the positions of candidate signals that took part in the coincidences, in their corresponding trigger files (\nN_{coin}\\times\n\n\nint\n) \n\n\n\n\nin order to recover the information about the original triggers for further studies. \n.coi\n files can be read with the auxilary \nread_coi\n code: \n\n\n% gcc -o read_coi read_coi.c -lm \n\n\n% ./read_coi \n\n# \nnum_of_coincidences\n    \nmean_val_of_pars\n \n(\nf\n,\n \ns\n,\n \nd\n,\n \na\n),\n \nsnr\n    \nframe_num\n:\ntrigger_num_in_trigger_file\n\n# \n(\nsee\n \nhttp\n:\n//\nmbejger\n.\ngithub\n.\nio\n/\npolgraw\n-\nallsky\n/\ncoincidences\n \nfor\n \ndetails\n)\n\n\n5\n \n9.956637e-01\n \n-\n1.108304e-09\n \n-\n1.125853e-01\n \n1.974630e+00\n \n1.246469e+01\n \n6\n:\n777\n \n2\n:\n708\n \n8\n:\n968\n \n3\n:\n701\n \n5\n:\n603\n \n\n3\n \n9.972902e-01\n \n-\n1.174760e-10\n \n-\n1.235594e-01\n \n1.968819e+00\n \n9.154494e+00\n \n8\n:\n983\n \n3\n:\n693\n \n1\n:\n669\n \n\n\n\n\n\nwhere the pairs \nframe-number:candidate-position-in-trigger-file\n have been arranged for readability.", 
            "title": "Coincidences between candidates"
        }, 
        {
            "location": "/coincidences/#coincidences-between-candidates", 
            "text": "In order to establish the probability of detection of a real gravitational wave, after finding the candidate signals with the  F-statistic candidate signal search , the pipeline searches for coincidences between candidates found in different time frames.   The coincidences code is available at  github . To get it, run  git clone https://github.com/mbejger/polgraw-allsky.git .", 
            "title": "Coincidences between candidates"
        }, 
        {
            "location": "/coincidences/#prerequisites", 
            "text": "The code is written in standard  C . The only dependency is  GNU Scientific Library (GSL) , used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues).  GNU struct dirent  objects are used to read the directories.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/coincidences/#the-idea-behind-coincidences", 
            "text": "After finding the candidate signals in different time frames ( search ), we want to confirm the existence of signals with the same parameters along the span of time segments. to further perform a validation search for high-coincidence, or otherwise interesting candidates (the  followup , currently under construction). To do this, the candidates from a list of trigger files (time frames) are read, and for each trigger file   a candidate is transformed to a well-defined time moment (frequency shifted to a reference frame),   translated into linear (integer) coordinates,   duplicates within each frame are removed,   list of unique candidates from all the frames is created and sorted,   duplicates are counted - these are the coincidences.    TODO: describe cell shifts (16 different shifts in total: 0101, 0110, 0010 etc. in f, s, d, a directions) and scaling of cells (used to define the linear parameters for a given cell to subsequently compare the candidate values)", 
            "title": "The idea behind coincidences"
        }, 
        {
            "location": "/coincidences/#compilation", 
            "text": "Run  make coincidences ; resulting binary is called  coincidences . Modify the  Makefile  to fit your system.", 
            "title": "Compilation"
        }, 
        {
            "location": "/coincidences/#full-list-of-switches", 
            "text": "Type   % ./coincidences --help    to obtain the following description:      Switch  Description      -data  Data directory (default is  ./candidates )    -output  Output directory (default is  ./coinc-results )    -shift  Cell shifts in  fsda  directions (4 digit number, e.g.  0101 , default  0000 )    -scale  Cell scaling in  fsda  directions (4 digit number, e.g.  4824 , default  1111 )    -refr  Reference frame number    -fpo  Reference band frequency  fpo  value    -dt  Data sampling time dt (default value:  0.5 )    -trigname  Part of triggers' name (for identifying files)    -refloc  Location of the reference grid.bin and starting_date files    -mincoin  Minimal number of coincidences recorded    -narrowdown  Narrow-down the frequency band (range [0, 0.5] +- around center)    -snrcutoff  Signal-to-noise threshold cutoff (default value: 6)     Also:           --help  This help", 
            "title": "Full list of switches"
        }, 
        {
            "location": "/coincidences/#example", 
            "text": "Using the software injection added to 2-day Gaussian noise data segments (see  minimal example of the pipeline ):  % for s in {0..1}{0..1}{0..1}{0..1}; do ./coincidences -data ../../search/network/src-cpu -output . -shift $s -scale 4444 -refr 4 -dt 2 -trigname 1234_2 -refloc ../../testdata/2d_0.25/004 -nod 2 -fpo 308.859375 -snrcutoff 5; done 2  summary   This assumes that for the band  bbbb=1234  and the sampling time  dt=2\\ \\mathrm{s}  the band frequency  fpo=308.859375\\ \\mathrm{Hz} , because  \nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}. \nThe reference grid file  grid.bin , corresponding to the reference frame  004  ( -refr 4 ) is located at the  -refloc  location. Signal-to-noise ratio cutoff is set to 5 ( -snrcutoff 5 ). Some output is directed to  stdin . For example, the output for shift  0000  is   Number of days is 2\nThe SNR threshold cutoff is 5.000000000000, corresponding to F-statistic value of 14.500000000000\nReading the reference grid.bin at ../../testdata/2d_0.25/004\nfftpad from the grid file: 1\nSettings dt: 2.000000, oms: 3881.241374\nReference frame number: 4\nCell shifts  in f, s, d, a directions: 0 0 0 0 \nCell scaling in f, s, d, a directions: 4 4 4 4 \nReading triggers... Frame 5: 1966/2040\nReading triggers... Frame 1: 2409/2483\nReading triggers... Frame 4: 2176/2384\nReading triggers... Frame 3: 2132/2247\nReading triggers... Frame 8: 2372/2408\nReading triggers... Frame 2: 2197/2249\nReading triggers... Frame 6: 2225/2305\nReading triggers... Frame 7: 2175/2226\nTotal number of candidates from all frames: 17652  The highest multiplicity coincidence for each shift is streamed to the  summary  file via the  stderr  ( 2  summary ). From this list of 16 lines, the highest multiplicity coincidence with the highest signal-to-noise is selected ( sort -gk5 -gk10 summary | tail -1 ):  1234_2 1111 308.859375     8     5  9.95663703e-01 -1.10830358e-09 -1.12585347e-01 1.97463002e+00 1.246469e+01 5 2040 1987 1 2483 2419 4 2384 2193 3 2247 2137 8 2408 2363 2 2249 2172 6 2305 2220 7 2226 2191 6 2 8 3 5  This output contains the    band_hemisphere  identifier ( 1234\\_2 ),   the  shift  value ( 1111 ),   the  fpo  reference band frequency ( 308.859375\\ \\mathrm{Hz} ),   the number of triggers files read ( 8 ),   the multiplicity of coincidence found ( N_{coin}=5 ),   arithmetic mean values of the frequency  \\bar{f}  (range  [0:2\\pi] , corresponding to the width of the band), mean frequency derivative  \\bar{s}  (spindown, in  Hz/s ), equatorial coordinate system sky positions  \\bar{\\delta}  ( [\\pi:-\\pi] ) and  \\bar{\\alpha}  ( [0:2\\pi] ), and the mean signal-to-noise ratio,  \\widetilde{\\mathrm{snr}}=\\sqrt{\\sum_i \\mathrm{snr}_i^2}  ( 5  floating-point numbers),   8 triplets of the frame number, number of all candidates in the corresponding triggers file, and the number of unique candidates after sorting to unique cells ( 8\\times 3  integers),   frame numbers participating in the coincidence ( 5  integers).    Coincidences larger or equal  mincoin  (default value  3 ) are recorded in binary files  .coi , separately for each shift, in the  -output  directory. Each coincidence is a set of following numbers:  \nN_{coin},\\quad\\bar{f},\\quad\\bar{s},\\quad\\bar{\\delta},\\quad\\bar{\\alpha},\\quad\\widetilde{\\mathrm{snr}},\\quad\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}},\\quad\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}} \nwhere     N_{coin}  is the multiplicity of coincidence (written as one  unsigned short int ),    \\bar{f} ,  \\bar{s} ,  \\bar{\\delta} ,  \\bar{\\alpha}  and  \\widetilde{\\mathrm{snr}}  are the mean parameters of the signal ( 5\\times  float ),   \\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}}  are the frame numbers ( N_{coin}\\times  unsigned short int ),    \\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}}  are the positions of candidate signals that took part in the coincidences, in their corresponding trigger files ( N_{coin}\\times  int )    in order to recover the information about the original triggers for further studies.  .coi  files can be read with the auxilary  read_coi  code:   % gcc -o read_coi read_coi.c -lm   % ./read_coi  \n#  num_of_coincidences      mean_val_of_pars   ( f ,   s ,   d ,   a ),   snr      frame_num : trigger_num_in_trigger_file \n#  ( see   http : // mbejger . github . io / polgraw - allsky / coincidences   for   details )  5   9.956637e-01   - 1.108304e-09   - 1.125853e-01   1.974630e+00   1.246469e+01   6 : 777   2 : 708   8 : 968   3 : 701   5 : 603   3   9.972902e-01   - 1.174760e-10   - 1.235594e-01   1.968819e+00   9.154494e+00   8 : 983   3 : 693   1 : 669    where the pairs  frame-number:candidate-position-in-trigger-file  have been arranged for readability.", 
            "title": "Example"
        }, 
        {
            "location": "/fap_coincidences/", 
            "text": "False alarm probability of coincidences\n\n\nA general formula for probability that is used in the estimation of significance of the coincidences is implemented. The code is available at \ngithub\n. Run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n to get the repository.\n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n. The only dependency is \nGNU Scientific Library (GSL)\n, used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues), the \n\\Gamma\n function and for the combinations. \n\n\nTheoretical description\n\n\nThis description is a short Appendix version of \nImplementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data\n. \n\n\nFor a given frequency band we analyze \nL\n non-overlapping time segments: the search in the \nl\nth segment produces \nN_l\n candidates. The size of the parameter space for each time segment is the same and it can be divided into the number \nN_{\\rm cell}\n of independent cells. The code tests the null hypothesis that the coincidences among candidates from \nL\n segments are accidental.\nThe probability for a candidate event to fall into any given coincidence cell is equal to \n1/N_{\\rm cell}\n. The probability \n\\epsilon_l\n that a given coincidence cell is populated with one or more candidate events is given by\n\n\n\\epsilon_l = 1 - \\Big(1 - \\frac{1}{N_{\\rm cell}}\\Big)^{N_l},  \n\\quad\\text{and for independent candidates (one candidate in one cell) it is}\\quad  \n\\epsilon_l = \\frac{N_l}{N_{\\rm cell}}. \n\n\nFor two or more candidates within a given cell we choose the one with the highest signal-to-noise ratio. The probability \np_F(N_{\\rm cell})\n that any given coincidence cell out of the total of \nN_{\\rm cell}\n cells contains candidate events from \nC_{max}\n or more distinct data segments is given by a generalized binomial distribution: \n\n\\begin{eqnarray}\np_F(N_{\\rm cell}) &=& \\sum_{n=C_{max}}^{L} \\frac{1}{n!(L-n)!} \\times \\sum_{\\sigma\\in\\Pi(L)} \\epsilon_{\\sigma(1)}\\ldots\\epsilon_{\\sigma(n)}(1-\\epsilon_{\\sigma(n+1)})\\ldots(1-\\epsilon_{\\sigma(L)}),\n\\end{eqnarray}\n\nwhere \n\\sum_{\\sigma \\in \\Pi(L)}\n is the sum over all permutations of \nL\n data sequences.\nFinally the probability \nP_F\n that there is \n{\\mathcal C}_{max}\n or more coincidences\nin one or more of the \nN_{\\rm cell}\n cells is\n\n\\begin{equation}\nP_F = 1 - \\left(1 - p_F(N_{\\rm cell})\\right)^{N_{\\rm cell}}.\n\\end{equation}\n\n\n\n\nIn order to find coincidences the entire cell coincidence grid is shifted by half a cell width in all possible \n2^4 = 16\n combinations of the four parameter-space dimensions of \n(f, \\dot{f}, \\delta, \\alpha)\n, and coincidences are searched in all the 16 coincidence grids. It does not account for cases when candidate events are located on opposite sides of cell borders, edges, and corners. This leads to a higher number of accidental coincidences, and consequently it underestimates the false alarm probability.\n\n\nIn the four dimension parameter space of \n(f, \\dot{f}, \\delta, \\alpha)\n the formula for the probability \nP^{\\rm shifts}_F\n that there are \n{\\mathcal C}_{\\mathrm{max}}\n or more independent coincidences in one or more of the \nN_{\\rm cell}\n cells in all 16 grid shifts is \n\n\\begin{eqnarray}\n\\label{eq:FAPs}\nP^{\\rm shifts}_F = 1 - \\bigg[ 1 - \\Big( 2^4 p_F(N_c) \n- \\Big( {4 \\choose 1} p_F(2 N_c) + {4 \\choose 2} p_F(2^2 N_c) \n+ {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c)   \\Big) \\\\ \\nonumber  \n- \\Big({4 \\choose 2} p_F(2^2 N_c) + {4 \\choose 3} p_F(2^3 N_c) \n+ {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- \\Big( {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- {4 \\choose 4} p_F(2^4 N_c)\\Big)  \\bigg]^{N_c}.\n\\end{eqnarray}\n\n\n\n\nBy choosing a certain false alarm probability \nP_F\n, we can calculate the threshold number \n{\\mathcal C}_{\\mathrm{max}}\n of coincidences. If we obtain more than \n{\\mathcal C}_{\\mathrm{max}}\n coincidences, the null hypothesis that coincidences are accidental is rejected at the significance level of \nP_F\n.\n\n\nCompilation\n\n\nRun \nmake fap\n; resulting binary is called \nfap\n (modify the \nMakefile\n to fit your system).\n\n\nFull list of switches\n\n\nTo obtain the full list of options, type \n\n\n% ./fap --help \n\n\n\n\n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-band\n\n\nBand number\n\n\n\n\n\n\n-cellsize\n\n\nCell size (default value: 4)\n\n\n\n\n\n\n-data\n\n\nCoincidence summary file\n\n\n\n\n\n\n-grid\n\n\nGrid matrix directory (default value: .)\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: 2)\n\n\n\n\n\n\n-threshold\n\n\nFAP threshold (default value: 0.1)\n\n\n\n\n\n\n-nod\n\n\nNumber of days\n\n\n\n\n\n\n-vetofrac\n\n\nVetoed fraction of the band (default value: 0)\n\n\n\n\n\n\n\n\nAlso:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\nExample\n\n\nUsing the software injection added to 2-day Gaussian noise data segments (see \nminimal example of the pipeline\n): \n\n\n% ./fap -nod \n2\n -band \n1234\n -data \n(\nsort -gk5 -gk10 summary \n|\n tail -1\n)\n -grid ../../testdata/2d_0.25/004 -vetofrac 0.0 -cellsize \n4\n -threshold 1.0 \n\n\n\n\n\nor, with the auxilary \nfap.sh\n script, \n\n\n% \nband\n=\n1234\n;\n bash fap.sh \n(\nsort -gk5 -gk10 summary \n|\n tail -1\n)\n \n(\necho\n \n$band\n 0.0\n)\n ../../testdata/2d_0.25/004 \n\n\n\n\n\nNumber of days in the time segment \nnod\n equals 2, fraction of the band vetoed \nvetofrac\n is 0 (no lines, Gaussian data) and the cell size scalling factor \ncellsize\n is 4. Directory containing the grid matrix file \ngrid.bin\n of the reference frame (in this case frame \n004\n) should be given by the \ngrid\n switch. The input data is the last line of a sorted \nsummary\n file to select the shift giving the best coincidence with the highest signal-to-noise ratio: \n\n\n1234_2 1111 308.859375     8     5  9.95663703e-01 -1.10830358e-09 -1.12585347e-01 1.97463002e+00 1.246469e+01 5 2040 1987 1 2483 2419 4 2384 2193 3 2247 2137 8 2408 2363 2 2249 2172 6 2305 2220 7 2226 2191 6 2 8 3 5\n\n\n\n\n\n(see the \ncoincidences\n section for details). \n\n\nOutput\n\n\n% ./fap -nod \n2\n -band \n1234\n -data \n(\nsort -gk5 -gk10 summary \n|\n tail -1\n)\n -grid ../../testdata/2d_0.25/004 -vetofrac 0.0 -cellsize \n4\n -threshold 1.0 \n\n\n\n\n\nis\n\n\nNumber of days in \ntime\n segments: 2\nInput data: /dev/fd/63\nGrid matrix data directory: ../../testdata/2d_0.25/004\nBand number: \n1234\n \n(\nveto fraction: 0.000000\n)\n\nThe reference frequency fpo: 308.859375\nThe data sampling \ntime\n dt: 2.000000\nFAP threshold: 1.000000\nCell size: 4\n\n1234\n 3.088594e+02 3.091094e+02 7.665713e-08 \n5\n \n17682\n 9.956637e-01 -1.108304e-09 -1.125853e-01 1.974630e+00 1.246469e+01 2\n\n\n\n\n\nThe last line (in case the probability \nPFshifts\n is lower than the \nthreshold\n) is printed to \nstderr\n. The meaning of this output is the following:  \n\n\n#band f_min       f_max        PFshifts     noc Nkall  f s d a hemisphere \n1234 3.088594e+02 3.091094e+02 7.665713e-08 5   17682  9.956637e-01 -1.108304e-09 -1.125853e-01 1.974630e+00 1.246469e+01 2", 
            "title": "False alarm probablity of conicidences"
        }, 
        {
            "location": "/fap_coincidences/#false-alarm-probability-of-coincidences", 
            "text": "A general formula for probability that is used in the estimation of significance of the coincidences is implemented. The code is available at  github . Run  git clone https://github.com/mbejger/polgraw-allsky.git  to get the repository.", 
            "title": "False alarm probability of coincidences"
        }, 
        {
            "location": "/fap_coincidences/#prerequisites", 
            "text": "The code is written in standard  C . The only dependency is  GNU Scientific Library (GSL) , used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues), the  \\Gamma  function and for the combinations.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/fap_coincidences/#theoretical-description", 
            "text": "This description is a short Appendix version of  Implementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data .   For a given frequency band we analyze  L  non-overlapping time segments: the search in the  l th segment produces  N_l  candidates. The size of the parameter space for each time segment is the same and it can be divided into the number  N_{\\rm cell}  of independent cells. The code tests the null hypothesis that the coincidences among candidates from  L  segments are accidental.\nThe probability for a candidate event to fall into any given coincidence cell is equal to  1/N_{\\rm cell} . The probability  \\epsilon_l  that a given coincidence cell is populated with one or more candidate events is given by \n\\epsilon_l = 1 - \\Big(1 - \\frac{1}{N_{\\rm cell}}\\Big)^{N_l},  \n\\quad\\text{and for independent candidates (one candidate in one cell) it is}\\quad  \n\\epsilon_l = \\frac{N_l}{N_{\\rm cell}}.  \nFor two or more candidates within a given cell we choose the one with the highest signal-to-noise ratio. The probability  p_F(N_{\\rm cell})  that any given coincidence cell out of the total of  N_{\\rm cell}  cells contains candidate events from  C_{max}  or more distinct data segments is given by a generalized binomial distribution:  \\begin{eqnarray}\np_F(N_{\\rm cell}) &=& \\sum_{n=C_{max}}^{L} \\frac{1}{n!(L-n)!} \\times \\sum_{\\sigma\\in\\Pi(L)} \\epsilon_{\\sigma(1)}\\ldots\\epsilon_{\\sigma(n)}(1-\\epsilon_{\\sigma(n+1)})\\ldots(1-\\epsilon_{\\sigma(L)}),\n\\end{eqnarray} \nwhere  \\sum_{\\sigma \\in \\Pi(L)}  is the sum over all permutations of  L  data sequences.\nFinally the probability  P_F  that there is  {\\mathcal C}_{max}  or more coincidences\nin one or more of the  N_{\\rm cell}  cells is \\begin{equation}\nP_F = 1 - \\left(1 - p_F(N_{\\rm cell})\\right)^{N_{\\rm cell}}.\n\\end{equation}   In order to find coincidences the entire cell coincidence grid is shifted by half a cell width in all possible  2^4 = 16  combinations of the four parameter-space dimensions of  (f, \\dot{f}, \\delta, \\alpha) , and coincidences are searched in all the 16 coincidence grids. It does not account for cases when candidate events are located on opposite sides of cell borders, edges, and corners. This leads to a higher number of accidental coincidences, and consequently it underestimates the false alarm probability.  In the four dimension parameter space of  (f, \\dot{f}, \\delta, \\alpha)  the formula for the probability  P^{\\rm shifts}_F  that there are  {\\mathcal C}_{\\mathrm{max}}  or more independent coincidences in one or more of the  N_{\\rm cell}  cells in all 16 grid shifts is  \\begin{eqnarray}\n\\label{eq:FAPs}\nP^{\\rm shifts}_F = 1 - \\bigg[ 1 - \\Big( 2^4 p_F(N_c) \n- \\Big( {4 \\choose 1} p_F(2 N_c) + {4 \\choose 2} p_F(2^2 N_c) \n+ {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c)   \\Big) \\\\ \\nonumber  \n- \\Big({4 \\choose 2} p_F(2^2 N_c) + {4 \\choose 3} p_F(2^3 N_c) \n+ {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- \\Big( {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- {4 \\choose 4} p_F(2^4 N_c)\\Big)  \\bigg]^{N_c}.\n\\end{eqnarray}   By choosing a certain false alarm probability  P_F , we can calculate the threshold number  {\\mathcal C}_{\\mathrm{max}}  of coincidences. If we obtain more than  {\\mathcal C}_{\\mathrm{max}}  coincidences, the null hypothesis that coincidences are accidental is rejected at the significance level of  P_F .", 
            "title": "Theoretical description"
        }, 
        {
            "location": "/fap_coincidences/#compilation", 
            "text": "Run  make fap ; resulting binary is called  fap  (modify the  Makefile  to fit your system).", 
            "title": "Compilation"
        }, 
        {
            "location": "/fap_coincidences/#full-list-of-switches", 
            "text": "To obtain the full list of options, type   % ./fap --help       Switch  Description      -band  Band number    -cellsize  Cell size (default value: 4)    -data  Coincidence summary file    -grid  Grid matrix directory (default value: .)    -dt  Data sampling time dt (default value: 2)    -threshold  FAP threshold (default value: 0.1)    -nod  Number of days    -vetofrac  Vetoed fraction of the band (default value: 0)     Also:           --help  This help", 
            "title": "Full list of switches"
        }, 
        {
            "location": "/fap_coincidences/#example", 
            "text": "Using the software injection added to 2-day Gaussian noise data segments (see  minimal example of the pipeline ):   % ./fap -nod  2  -band  1234  -data  ( sort -gk5 -gk10 summary  |  tail -1 )  -grid ../../testdata/2d_0.25/004 -vetofrac 0.0 -cellsize  4  -threshold 1.0   or, with the auxilary  fap.sh  script,   %  band = 1234 ;  bash fap.sh  ( sort -gk5 -gk10 summary  |  tail -1 )   ( echo   $band  0.0 )  ../../testdata/2d_0.25/004   Number of days in the time segment  nod  equals 2, fraction of the band vetoed  vetofrac  is 0 (no lines, Gaussian data) and the cell size scalling factor  cellsize  is 4. Directory containing the grid matrix file  grid.bin  of the reference frame (in this case frame  004 ) should be given by the  grid  switch. The input data is the last line of a sorted  summary  file to select the shift giving the best coincidence with the highest signal-to-noise ratio:   1234_2 1111 308.859375     8     5  9.95663703e-01 -1.10830358e-09 -1.12585347e-01 1.97463002e+00 1.246469e+01 5 2040 1987 1 2483 2419 4 2384 2193 3 2247 2137 8 2408 2363 2 2249 2172 6 2305 2220 7 2226 2191 6 2 8 3 5  (see the  coincidences  section for details).", 
            "title": "Example"
        }, 
        {
            "location": "/fap_coincidences/#output", 
            "text": "% ./fap -nod  2  -band  1234  -data  ( sort -gk5 -gk10 summary  |  tail -1 )  -grid ../../testdata/2d_0.25/004 -vetofrac 0.0 -cellsize  4  -threshold 1.0   is  Number of days in  time  segments: 2\nInput data: /dev/fd/63\nGrid matrix data directory: ../../testdata/2d_0.25/004\nBand number:  1234   ( veto fraction: 0.000000 ) \nThe reference frequency fpo: 308.859375\nThe data sampling  time  dt: 2.000000\nFAP threshold: 1.000000\nCell size: 4 1234  3.088594e+02 3.091094e+02 7.665713e-08  5   17682  9.956637e-01 -1.108304e-09 -1.125853e-01 1.974630e+00 1.246469e+01 2  The last line (in case the probability  PFshifts  is lower than the  threshold ) is printed to  stderr . The meaning of this output is the following:    #band f_min       f_max        PFshifts     noc Nkall  f s d a hemisphere \n1234 3.088594e+02 3.091094e+02 7.665713e-08 5   17682  9.956637e-01 -1.108304e-09 -1.125853e-01 1.974630e+00 1.246469e+01 2", 
            "title": "Output"
        }, 
        {
            "location": "/followup/", 
            "text": "Followup\n\n\nCurrently work in progress; for the present state of the code see \nhere\n. \n\n\nIntroduction\n\n\nOn the last stage we can precisely estimate signal parameters. At this stage we focus only on a very narrow space around a candidate. Our goal is to find the maximum of the F-statistic and the corresponding signal parameters. To increase the efficiency of the code, we use special libraries (\nGNU Scientific Library (GSL)\n, \nYEPPP!\n) and parallelisation (\nOpenMP\n). We already implemented few algorithms to do this: Simplex algorithm, Mesh Adaptive Direct Search - MADS and modified MADS (called 'inverted MADS').\n\n\nCompilation\n\n\nTo compile a code, go to the \nfollowup/src\n and run: \nmake followup\n\n\nSwitches\n\n\nRun \n./followup --help\n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-d, -data\n\n\nData directory (default is .)\n\n\n\n\n\n\n-o, -output\n\n\nOutput directory (default is ./candidates)\n\n\n\n\n\n\n-i, -ident\n\n\nFrame number\n\n\n\n\n\n\n-b, -band\n\n\nBand number\n\n\n\n\n\n\n-l, -label\n\n\nCustom label for the input and output files\n\n\n\n\n\n\n-c, -cwd\n\n\nChange to directory [dir]\n\n\n\n\n\n\n-t, -threshold\n\n\nThreshold for the F-statistic (default is 20)\n\n\n\n\n\n\n-p, -fpo\n\n\nReference band frequency fpo value\n\n\n\n\n\n\n-s, -dt\n\n\nData sampling time dt (default value: 0.5)\n\n\n\n\n\n\n-u, -usedet\n\n\nUse only detectors from string (default is use all available)\n\n\n\n\n\n\n-y, -nod\n\n\nNumber of days\n\n\n\n\n\n\n-x, -addsig\n\n\nAdd signal with parameters from [file]\n\n\n\n\n\n\n-a, -candidates\n\n\nAs a starting point in followup use parameters from [file]\n\n\n\n\n\n\n-r, -refr\n\n\nReference frame number\n\n\n\n\n\n\n\n\nAlso:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--vetolines\n\n\nVeto known lines from files in data directory\n\n\n\n\n\n\n--simplex\n\n\nDirect search of maximum using Nelder-Mead (simplex) algorithm\n\n\n\n\n\n\n--mads\n\n\nDirect search of maximum using MADS algorithm\n\n\n\n\n\n\n--gauss\n\n\nGenerate Gaussian noise instead of reading data. Amplitude and sigma of the noise declared in init.c\n\n\n\n\n\n\n--neigh\n\n\nFunction neigh() generate area as % from initial value instead of taking it from grid.bin\n\n\n\n\n\n\n--naive\n\n\nFunction naive() generate area as +/- points taking it from grid.bin and divide it into smaller grid.\n\n\n\n\n\n\n--onepoint\n\n\nCalculate Fstatistic only in one point taken from file with candidates (without generating any grid).\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\nBy default code is searching maximum of the F-statistic on the optimal, 4-dimensional grid (parameters of the grid, like e.g. minimal match, ale defined inside the code, in \nfollowup.c\n). Main idea was to search on a denser grid than in \nsearch\n code, but to focus only on a few points around candidate. Additionally, when the point (on the optimal grid) with the maximal value of the F-statistic is established, one can run one of the direct maximum search algorithm: Nelder-Mead (\n--simplex\n switch) or MADS (\n--mads\n switch), to determine parameters of the maximum more precisely. In the current version of the code, by using \n--mads\n switch, one will use modified, 'inverted' MADS. To skip calculations on the optimal grid and run one of the algorithms directly from the initial point, use \n--onepoint\n switch.\n\n\nInput data\n\n\nFiles required to run the code: \nxdatc*\n, \nDetSSB.bin\n and \ngrid.bin\n. Path to the directory is taken from \n-data\n switch; there directories named as \niii/H1\n,\niii/L1\n etc. are expected, where \niii\n is a frame number taken from \n-ident\n switch.\n\n\nInitial point of the calculations (switch \n-candidates\n) is required. Usually the best result from coincidences (previous step of the pipeline) is taken. Parameters of the candidate need to be written into the file, as:\n\n\nfrequency spin-down declination right_ascension\n\n\nMinimal example how to run a code\n\n\nRun: \n\n\nLD_LIBRARY_PATH\n=\n../../search/network/src-cpu/lib/yeppp-1.0.0/binaries/linux/x86_64 ./followup -data data_path/ -band \n0666\n -dt \n16\n -candidates path_to_candidate/candidate.txt -ident \n001\n -nod \n6\n --mads\n output.txt \n\n\n\n\n\nAs a result (last line in the output file) one can get parameters of the found maximum:\n\n\nfrequency spin-down declination right_ascension F-statistic_value SNR", 
            "title": "Followup of interesting outliers"
        }, 
        {
            "location": "/followup/#followup", 
            "text": "Currently work in progress; for the present state of the code see  here .", 
            "title": "Followup"
        }, 
        {
            "location": "/followup/#introduction", 
            "text": "On the last stage we can precisely estimate signal parameters. At this stage we focus only on a very narrow space around a candidate. Our goal is to find the maximum of the F-statistic and the corresponding signal parameters. To increase the efficiency of the code, we use special libraries ( GNU Scientific Library (GSL) ,  YEPPP! ) and parallelisation ( OpenMP ). We already implemented few algorithms to do this: Simplex algorithm, Mesh Adaptive Direct Search - MADS and modified MADS (called 'inverted MADS').", 
            "title": "Introduction"
        }, 
        {
            "location": "/followup/#compilation", 
            "text": "To compile a code, go to the  followup/src  and run:  make followup", 
            "title": "Compilation"
        }, 
        {
            "location": "/followup/#switches", 
            "text": "Run  ./followup --help     Switch  Description      -d, -data  Data directory (default is .)    -o, -output  Output directory (default is ./candidates)    -i, -ident  Frame number    -b, -band  Band number    -l, -label  Custom label for the input and output files    -c, -cwd  Change to directory [dir]    -t, -threshold  Threshold for the F-statistic (default is 20)    -p, -fpo  Reference band frequency fpo value    -s, -dt  Data sampling time dt (default value: 0.5)    -u, -usedet  Use only detectors from string (default is use all available)    -y, -nod  Number of days    -x, -addsig  Add signal with parameters from [file]    -a, -candidates  As a starting point in followup use parameters from [file]    -r, -refr  Reference frame number     Also:           --vetolines  Veto known lines from files in data directory    --simplex  Direct search of maximum using Nelder-Mead (simplex) algorithm    --mads  Direct search of maximum using MADS algorithm    --gauss  Generate Gaussian noise instead of reading data. Amplitude and sigma of the noise declared in init.c    --neigh  Function neigh() generate area as % from initial value instead of taking it from grid.bin    --naive  Function naive() generate area as +/- points taking it from grid.bin and divide it into smaller grid.    --onepoint  Calculate Fstatistic only in one point taken from file with candidates (without generating any grid).    --help  This help     By default code is searching maximum of the F-statistic on the optimal, 4-dimensional grid (parameters of the grid, like e.g. minimal match, ale defined inside the code, in  followup.c ). Main idea was to search on a denser grid than in  search  code, but to focus only on a few points around candidate. Additionally, when the point (on the optimal grid) with the maximal value of the F-statistic is established, one can run one of the direct maximum search algorithm: Nelder-Mead ( --simplex  switch) or MADS ( --mads  switch), to determine parameters of the maximum more precisely. In the current version of the code, by using  --mads  switch, one will use modified, 'inverted' MADS. To skip calculations on the optimal grid and run one of the algorithms directly from the initial point, use  --onepoint  switch.", 
            "title": "Switches"
        }, 
        {
            "location": "/followup/#input-data", 
            "text": "Files required to run the code:  xdatc* ,  DetSSB.bin  and  grid.bin . Path to the directory is taken from  -data  switch; there directories named as  iii/H1 , iii/L1  etc. are expected, where  iii  is a frame number taken from  -ident  switch.  Initial point of the calculations (switch  -candidates ) is required. Usually the best result from coincidences (previous step of the pipeline) is taken. Parameters of the candidate need to be written into the file, as:  frequency spin-down declination right_ascension", 
            "title": "Input data"
        }, 
        {
            "location": "/followup/#minimal-example-how-to-run-a-code", 
            "text": "Run:   LD_LIBRARY_PATH = ../../search/network/src-cpu/lib/yeppp-1.0.0/binaries/linux/x86_64 ./followup -data data_path/ -band  0666  -dt  16  -candidates path_to_candidate/candidate.txt -ident  001  -nod  6  --mads  output.txt   As a result (last line in the output file) one can get parameters of the found maximum:  frequency spin-down declination right_ascension F-statistic_value SNR", 
            "title": "Minimal example how to run a code"
        }, 
        {
            "location": "/sensitivity_upper_limits/", 
            "text": "Sensitivity upper limits\n\n\nThis directory contains a set of scripts that prepare and run a pipeline search in a small area in the parameter space around the injected signal. \n\n\nPrerequisites\n\n\nThe scripts require \npython3\n. A working solution is to install a \npython\n virtual environment (\npython3\n comes with a built-in \npyvenv\n virtual environment software).  \n\n\nInstall \npython3.4.5\n locally\n\n\nLet's assume the installation directory is  \n\n\ninstalldir\n=\n/path/to/installdir\n\n\n\n\n\nthen \n\n\nmkdir -p \n${\ninstalldir\n}\n;\n \ncd\n \n${\ninstalldir\n}\n \nwget https://www.python.org/ftp/python/3.4.5/Python-3.4.5.tgz\ntar zxvf Python-3.4.5.tgz\n\ncd\n Python-3.4.5\nmake clean\n./configure --prefix\n=\n$(\ndirname \n${\nPWD\n}\n)\n \nmake -j4\nmake install\n\ncd\n ../\n;\n rm -fr Python-3.4.5*\n\n\n\n\n\nCreate virtual environment\n\n\nIn a selected location (\n/path/to/venvdir\n) type\n\n\n${\ninstalldir\n}\n/bin/pyvenv venv\n\n\n\n\n\nActivate the virtual environment\n\n\n. /path/to/venvdir/bin/activate\n\n\n\n\n\n(to leave the environment, type \ndeactivate\n). You can now install specific packages using the \npip\n installer: \n\n\npip install nympy\npip install scipy\npip install matplotlib\npip install pandas\n\n\n\n\n\nRunning the scripts\n\n\nThe steps of the procedure is as follows:\n\n\n\n\nChose the GW strain amplitude \nh_0\n,\n\n\nRandomly chose other signal parameters (with signal generator \nsigen\n)\n\n\nAdd signal to the data (with the \ngwdetect-cpu --addsig\n feature) to selected time segments, and perform the search for candidates in each of them (\ngwdetect-cpu\n),\n\n\nSearch for coincidences (\ncoincidences\n)\n\n\nFind if the signal was detected (find the highest coincidences for a given band and compare them with the number of time segments analyzed).\n\n\n\n\nThe script \nscript.py\n creates a subdirectory in which the pipeline will be launched based on the following input files:\n1. \nconfig.ini\n which contains the paths to codes and the input data, and the parameters of the search: \n    * F-statistic threshold, \n    * how many simulations, \n    * which detectors to use, \n    * size of the region to search, \n    * how to perform the search for coincidences etc. \n\n\n\n\nbandlist\n which is a list of bands with strain amplitudes, for example:  \n\n\n\n\n0164\n 2.25e-1 \n\n0165\n 1.5e-1 2e-1 2.5e-1 3e-1\n\n0166\n 2e-1 4e-1\n\n\n\n\n\nThe call is\n\n\n% python script.py config.ini bandlist\n\n\n\n\n\nTwo other auxiliary files are:\n1. Dummy \nbash\n script \ndummy.sh\n with the actual pipeline calls (variables replaced with actual values by \nscript.py\n and renamed to \nscript.sh\n),\n2. \nPBS/Torque\n script \njob.sub\n, launched into the cluster queue and running \nscript.sh\n (modify it to fit other systems, e.g., the \nslurm\n scheduler). \n\n\nScript \nscript.py\n creates a \nrun.sh\n file which contains commands to send the jobs into the queue. The results are summary files (\n.sum\n) for the requested number of simulations. In order to process them, call the \nsummary.py\n script\n\n\n% python summary.py band coincidence_threshold number_of_simulations\n\n\n\n\n\nfor example \n\n\n% python summary.py \n0165\n 0.7 100\n\n\n\n\n\nThe result will be something as follows (columns are \nband\n number, amplitude \nh\n, upper limit \nul\n): \n\n\nband h   ul \n\n0165\n 0.150 0.61\n\n0165\n 0.200 0.78\n\n0165\n 0.250 0.95\n\n0165\n 0.300 0.99\n\n\n\n\n\nSerial (stacked) version for longer jobs\n\n\nscript2.py\n creates subdirectories and a \njob_BAND.sub\n file for a list of amplitudes for BAND from \nbandlist\n, stacked one after another (can be handy to send one band as one job to the queue). Call: \n\n\n% python script2.sh config.ini bandlist\n\n\n\n\n\nand then (for e.g., band 0165) send it to the queue \n\n\n% qsub -N \n0165\n -v \nhowmany\n=\n100\n job_0165.sub\n\n\n\n\n\nThe summary of simulations for a given band (\n0165\n, say) processed by the \nsummary.sh\n result in the following list of \nh0\n amplitudes followed by the corresponding fractions of significant coincidences (\nN_coin/N\n):\n\n\nband h   ul \n\n0165\n 0.150 0.61\n\n0165\n 0.200 0.78\n\n0165\n 0.250 0.95\n\n0165\n 0.300 0.99\n\n\n\n\n\nWe are interested in a 95% upper limit i.e. the \nh0\n corresponding to the fraction 0.95 of significant coincidences in the simulation (\nN_coin/N=0.95\n). This is obtained by fitting a sigmoid function\n\n\ndef\n \nsigmoid\n(\nx\n,\n \nx0\n,\n \nk\n):\n\n     \ny\n \n=\n \n1.0\n \n/\n \n(\n1.0\n \n+\n \nnp\n.\nexp\n(\nk\n*\n(\nx0\n-\nx\n)))\n\n     \nreturn\n \ny\n\n\n\n\n\n\nto the above data. Fitting is done by \nul.py\n:\n\n\n% python ul.py 0165_results \n0165\n 0.01 test.pdf\n\n0165\n 2.7026e-01\n\n\n\n\n\nThe output is the band number and \nh0\n corresponding to the 95% upper limit. Last command-line option \ntest.pdf\n is optional. It produces the auxiliary plot, with the 95% upper limit is denoted by red circle:", 
            "title": "Sensitivity upper limits"
        }, 
        {
            "location": "/sensitivity_upper_limits/#sensitivity-upper-limits", 
            "text": "This directory contains a set of scripts that prepare and run a pipeline search in a small area in the parameter space around the injected signal.", 
            "title": "Sensitivity upper limits"
        }, 
        {
            "location": "/sensitivity_upper_limits/#prerequisites", 
            "text": "The scripts require  python3 . A working solution is to install a  python  virtual environment ( python3  comes with a built-in  pyvenv  virtual environment software).", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/sensitivity_upper_limits/#install-python345-locally", 
            "text": "Let's assume the installation directory is    installdir = /path/to/installdir  then   mkdir -p  ${ installdir } ;   cd   ${ installdir }  \nwget https://www.python.org/ftp/python/3.4.5/Python-3.4.5.tgz\ntar zxvf Python-3.4.5.tgz cd  Python-3.4.5\nmake clean\n./configure --prefix = $( dirname  ${ PWD } )  \nmake -j4\nmake install cd  ../ ;  rm -fr Python-3.4.5*", 
            "title": "Install python3.4.5 locally"
        }, 
        {
            "location": "/sensitivity_upper_limits/#create-virtual-environment", 
            "text": "In a selected location ( /path/to/venvdir ) type  ${ installdir } /bin/pyvenv venv  Activate the virtual environment  . /path/to/venvdir/bin/activate  (to leave the environment, type  deactivate ). You can now install specific packages using the  pip  installer:   pip install nympy\npip install scipy\npip install matplotlib\npip install pandas", 
            "title": "Create virtual environment"
        }, 
        {
            "location": "/sensitivity_upper_limits/#running-the-scripts", 
            "text": "The steps of the procedure is as follows:   Chose the GW strain amplitude  h_0 ,  Randomly chose other signal parameters (with signal generator  sigen )  Add signal to the data (with the  gwdetect-cpu --addsig  feature) to selected time segments, and perform the search for candidates in each of them ( gwdetect-cpu ),  Search for coincidences ( coincidences )  Find if the signal was detected (find the highest coincidences for a given band and compare them with the number of time segments analyzed).   The script  script.py  creates a subdirectory in which the pipeline will be launched based on the following input files:\n1.  config.ini  which contains the paths to codes and the input data, and the parameters of the search: \n    * F-statistic threshold, \n    * how many simulations, \n    * which detectors to use, \n    * size of the region to search, \n    * how to perform the search for coincidences etc.    bandlist  which is a list of bands with strain amplitudes, for example:     0164  2.25e-1  0165  1.5e-1 2e-1 2.5e-1 3e-1 0166  2e-1 4e-1  The call is  % python script.py config.ini bandlist  Two other auxiliary files are:\n1. Dummy  bash  script  dummy.sh  with the actual pipeline calls (variables replaced with actual values by  script.py  and renamed to  script.sh ),\n2.  PBS/Torque  script  job.sub , launched into the cluster queue and running  script.sh  (modify it to fit other systems, e.g., the  slurm  scheduler).   Script  script.py  creates a  run.sh  file which contains commands to send the jobs into the queue. The results are summary files ( .sum ) for the requested number of simulations. In order to process them, call the  summary.py  script  % python summary.py band coincidence_threshold number_of_simulations  for example   % python summary.py  0165  0.7 100  The result will be something as follows (columns are  band  number, amplitude  h , upper limit  ul ):   band h   ul  0165  0.150 0.61 0165  0.200 0.78 0165  0.250 0.95 0165  0.300 0.99", 
            "title": "Running the scripts"
        }, 
        {
            "location": "/sensitivity_upper_limits/#serial-stacked-version-for-longer-jobs", 
            "text": "script2.py  creates subdirectories and a  job_BAND.sub  file for a list of amplitudes for BAND from  bandlist , stacked one after another (can be handy to send one band as one job to the queue). Call:   % python script2.sh config.ini bandlist  and then (for e.g., band 0165) send it to the queue   % qsub -N  0165  -v  howmany = 100  job_0165.sub  The summary of simulations for a given band ( 0165 , say) processed by the  summary.sh  result in the following list of  h0  amplitudes followed by the corresponding fractions of significant coincidences ( N_coin/N ):  band h   ul  0165  0.150 0.61 0165  0.200 0.78 0165  0.250 0.95 0165  0.300 0.99  We are interested in a 95% upper limit i.e. the  h0  corresponding to the fraction 0.95 of significant coincidences in the simulation ( N_coin/N=0.95 ). This is obtained by fitting a sigmoid function  def   sigmoid ( x ,   x0 ,   k ): \n      y   =   1.0   /   ( 1.0   +   np . exp ( k * ( x0 - x ))) \n      return   y   to the above data. Fitting is done by  ul.py :  % python ul.py 0165_results  0165  0.01 test.pdf 0165  2.7026e-01  The output is the band number and  h0  corresponding to the 95% upper limit. Last command-line option  test.pdf  is optional. It produces the auxiliary plot, with the 95% upper limit is denoted by red circle:", 
            "title": "Serial (stacked) version for longer jobs"
        }, 
        {
            "location": "/fisher/", 
            "text": "Fisher matrix calculation\n\n\nThe Fisher matrix associated with the signal model and its inversion is calculated using \nthis code\n. \n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n and it's mostly based on functions used in \nsearch\n. Arbitrary-precision interval arithmetic \nArb\n library is used to invert the (usually) not-very-well posed Fisher matrix, so it has to be installed beforehand. \nArb\n requires \nFLINT\n, \nMPFR\n, and either \nMPIR\n or \nGMP\n. \n\n\nCompilation\n\n\nRun  \nmake fisher\n in \nsearch/network/src-cpu\n - resulting  binary is called \nfisher\n. Modify the \nMakefile\n (especially the variable \nARB_DIR\n) to fit your system. \n\n\n\n\nFull list of switches\n\n\nFor the full list of options, type\n\n\n% ./fisher --help \n\n\n\n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-data\n\n\nData directory (default is \n.\n)\n\n\n\n\n\n\n-ident\n\n\nFrame number\n\n\n\n\n\n\n-band\n\n\nBand number\n\n\n\n\n\n\n-fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-usedet\n\n\nUse only detectors from string (default is \nuse all available\n)\n\n\n\n\n\n\n-addsig\n\n\nAdd signal with parameters from \nfile\n\n\n\n\n\n\n\n\nAlso: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\nExample\n\n\nMinimal call to \nfisher\n is as follows: \n\n\n% ./fisher -data 2d_0.25 -ident 001 -band 1234 -usedet H1 -dt 2 -nod 2 -addsig sigfile\n\n\n\n\n\n\nwhere\n\n\n\n\ndata\n is the base directory of input data files (e.g., \nthis Gaussian data\n),\n\n\nSampling time \ndt\n is \n2 s\n, \n\n\nident\n is the number of time frame to be analyzed (\n001\n),\n\n\nnod\n number of days is \n2\n, \n\n\nband\n is the number of the frequency band (see the \ninput data structure\n for details). \n\n\nusedet\n switch to chose a detector (here \nH1\n) \n\n\naddsig\n switch to chose a file with signal data\n\n\n\n\nThe \nsigfile\n file consists of 8 numbers: \n\n\n\n\nfrequency [radians, between 0 and \n\\pi\n] above \nfpo\n  \n\n\nspindown (frequency time derivative) [\n\\mathrm{Hz/s}\n]  \n\n\ndeclination [radians, between \n\\pi\n and \n-\\pi\n]\n\n\nright ascension [radians, between 0 and \n2\\pi\n]\n\n\n4 amplitudes \na_1, a_2, a_3, a_4\n\n\n\n\n\n\ne.g., \n\n\n1.431318175386891\n-7.9539e-9\n0.6363615896875658\n4.396884357060633\n7.764354801848407e-3\n-1.422468474545797e-2\n-1.559826840666228e-2\n-8.623005535014139e-3\n\n\n\n\n\nThe amplitudes \na_1, a_2, a_3, a_4\n correspond to the signal \namplitude model \n\n\n\n\n \nh = a_1 h_1 + a_2 h_2 + a_3 h_3 + a_4 h_4, \n\n\n\n\n\nwhere \n\n\n\n\n\nh(t) = \\left(a_1 a(t) + a_2 b(t)\\right)\\cos(\\psi) \n+ \\left(a_3 a(t) + a_4 b(t)\\right)sin(\\psi), \n\n\n\n\n\nwith \n\\psi(f, \\dot{f}, \\delta, \\alpha, t)\n being the phase of the signal, and \na\n and \nb\n the amplitude modulation functions (calculated in the \nmodvir\n function). \n\n\nExample output\n\n\nNumber of days is 2\nInput data directory is 2d_0.25\nFrame and band numbers are \n1\n and 1234\nThe reference frequency fpo is 308.859375\nThe data sampling \ntime\n dt is 2.000000\nAdding signal from \nsigfile\n\nSettings - number of detectors: 1\nUsing H1 IFO as detector \n#0... 2d_0.25/001/H1/xdatc_001_1234.bin as input time series data\n\nUsing 2d_0.25/001/H1/DetSSB.bin as detector H1 ephemerids...\nThe Fisher matrix:\n1.4602194451385117e+10 9.6224528459395950e+14 1.0472943290223141e+10 1.9109038902196317e+11 -5.6465717962684985e+06 -4.1172082782989331e+06 -2.9517981884375727e+06 7.0470722915177587e+06 \n9.6224528459395950e+14 6.7134859540063060e+19 6.5156368686556762e+14 1.1289208033400466e+16 -3.3340781322676825e+11 -2.4401458951787103e+11 -1.7381344007331134e+11 4.1673668536337537e+11 \n1.0472943290223141e+10 6.5156368686556762e+14 8.0545511145922174e+09 1.5540065972734366e+11 -4.6112260504154256e+06 -3.4059196396034071e+06 -2.3414307185722976e+06 5.7018637665277841e+06 \n1.9109038902196317e+11 1.1289208033400466e+16 1.5540065972734366e+11 3.1204237328935298e+12 -9.2852217833914995e+07 -6.9173973293523684e+07 -4.6213130625602841e+07 1.1410003283718885e+08 \n-5.6465717962684985e+06 -3.3340781322676825e+11 -4.6112260504154256e+06 -9.2852217833914995e+07 7.6814199126393523e+03 -1.6833193661163169e-03 0.0000000000000000e+00 0.0000000000000000e+00 \n-4.1172082782989331e+06 -2.4401458951787103e+11 -3.4059196396034071e+06 -6.9173973293523684e+07 -1.6833193661163169e-03 1.0351065428550139e+04 0.0000000000000000e+00 0.0000000000000000e+00 \n-2.9517981884375727e+06 -1.7381344007331134e+11 -2.3414307185722976e+06 -4.6213130625602841e+07 0.0000000000000000e+00 0.0000000000000000e+00 7.6814199126393523e+03 -1.6833193661163169e-03 \n7.0470722915177587e+06 4.1673668536337537e+11 5.7018637665277841e+06 1.1410003283718885e+08 0.0000000000000000e+00 0.0000000000000000e+00 -1.6833193661163169e-03 1.0351065428550139e+04 \nInverting the Fisher matrix...\nDiagonal elements of the covariance matrix:\n2.561275e-04 3.867944e-18 2.363103e-03 9.137957e-04 1.343874e+05 4.107046e+04 3.329715e+04 1.117611e+05", 
            "title": "Fisher matrix calculation"
        }, 
        {
            "location": "/fisher/#fisher-matrix-calculation", 
            "text": "The Fisher matrix associated with the signal model and its inversion is calculated using  this code .", 
            "title": "Fisher matrix calculation"
        }, 
        {
            "location": "/fisher/#prerequisites", 
            "text": "The code is written in standard  C  and it's mostly based on functions used in  search . Arbitrary-precision interval arithmetic  Arb  library is used to invert the (usually) not-very-well posed Fisher matrix, so it has to be installed beforehand.  Arb  requires  FLINT ,  MPFR , and either  MPIR  or  GMP .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/fisher/#compilation", 
            "text": "Run   make fisher  in  search/network/src-cpu  - resulting  binary is called  fisher . Modify the  Makefile  (especially the variable  ARB_DIR ) to fit your system.", 
            "title": "Compilation"
        }, 
        {
            "location": "/fisher/#full-list-of-switches", 
            "text": "For the full list of options, type  % ./fisher --help      Switch  Description      -data  Data directory (default is  . )    -ident  Frame number    -band  Band number    -fpo  Reference band frequency  fpo  value    -dt  Data sampling time dt (default value:  0.5 )    -usedet  Use only detectors from string (default is  use all available )    -addsig  Add signal with parameters from  file     Also:            --help  This help", 
            "title": "Full list of switches"
        }, 
        {
            "location": "/fisher/#example", 
            "text": "Minimal call to  fisher  is as follows:   % ./fisher -data 2d_0.25 -ident 001 -band 1234 -usedet H1 -dt 2 -nod 2 -addsig sigfile   where   data  is the base directory of input data files (e.g.,  this Gaussian data ),  Sampling time  dt  is  2 s ,   ident  is the number of time frame to be analyzed ( 001 ),  nod  number of days is  2 ,   band  is the number of the frequency band (see the  input data structure  for details).   usedet  switch to chose a detector (here  H1 )   addsig  switch to chose a file with signal data   The  sigfile  file consists of 8 numbers:    frequency [radians, between 0 and  \\pi ] above  fpo     spindown (frequency time derivative) [ \\mathrm{Hz/s} ]    declination [radians, between  \\pi  and  -\\pi ]  right ascension [radians, between 0 and  2\\pi ]  4 amplitudes  a_1, a_2, a_3, a_4    e.g.,   1.431318175386891\n-7.9539e-9\n0.6363615896875658\n4.396884357060633\n7.764354801848407e-3\n-1.422468474545797e-2\n-1.559826840666228e-2\n-8.623005535014139e-3  The amplitudes  a_1, a_2, a_3, a_4  correspond to the signal \namplitude model     \nh = a_1 h_1 + a_2 h_2 + a_3 h_3 + a_4 h_4,    where    \nh(t) = \\left(a_1 a(t) + a_2 b(t)\\right)\\cos(\\psi) \n+ \\left(a_3 a(t) + a_4 b(t)\\right)sin(\\psi),    with  \\psi(f, \\dot{f}, \\delta, \\alpha, t)  being the phase of the signal, and  a  and  b  the amplitude modulation functions (calculated in the  modvir  function).", 
            "title": "Example"
        }, 
        {
            "location": "/fisher/#example-output", 
            "text": "Number of days is 2\nInput data directory is 2d_0.25\nFrame and band numbers are  1  and 1234\nThe reference frequency fpo is 308.859375\nThe data sampling  time  dt is 2.000000\nAdding signal from  sigfile \nSettings - number of detectors: 1\nUsing H1 IFO as detector  #0... 2d_0.25/001/H1/xdatc_001_1234.bin as input time series data \nUsing 2d_0.25/001/H1/DetSSB.bin as detector H1 ephemerids...\nThe Fisher matrix:\n1.4602194451385117e+10 9.6224528459395950e+14 1.0472943290223141e+10 1.9109038902196317e+11 -5.6465717962684985e+06 -4.1172082782989331e+06 -2.9517981884375727e+06 7.0470722915177587e+06 \n9.6224528459395950e+14 6.7134859540063060e+19 6.5156368686556762e+14 1.1289208033400466e+16 -3.3340781322676825e+11 -2.4401458951787103e+11 -1.7381344007331134e+11 4.1673668536337537e+11 \n1.0472943290223141e+10 6.5156368686556762e+14 8.0545511145922174e+09 1.5540065972734366e+11 -4.6112260504154256e+06 -3.4059196396034071e+06 -2.3414307185722976e+06 5.7018637665277841e+06 \n1.9109038902196317e+11 1.1289208033400466e+16 1.5540065972734366e+11 3.1204237328935298e+12 -9.2852217833914995e+07 -6.9173973293523684e+07 -4.6213130625602841e+07 1.1410003283718885e+08 \n-5.6465717962684985e+06 -3.3340781322676825e+11 -4.6112260504154256e+06 -9.2852217833914995e+07 7.6814199126393523e+03 -1.6833193661163169e-03 0.0000000000000000e+00 0.0000000000000000e+00 \n-4.1172082782989331e+06 -2.4401458951787103e+11 -3.4059196396034071e+06 -6.9173973293523684e+07 -1.6833193661163169e-03 1.0351065428550139e+04 0.0000000000000000e+00 0.0000000000000000e+00 \n-2.9517981884375727e+06 -1.7381344007331134e+11 -2.3414307185722976e+06 -4.6213130625602841e+07 0.0000000000000000e+00 0.0000000000000000e+00 7.6814199126393523e+03 -1.6833193661163169e-03 \n7.0470722915177587e+06 4.1673668536337537e+11 5.7018637665277841e+06 1.1410003283718885e+08 0.0000000000000000e+00 0.0000000000000000e+00 -1.6833193661163169e-03 1.0351065428550139e+04 \nInverting the Fisher matrix...\nDiagonal elements of the covariance matrix:\n2.561275e-04 3.867944e-18 2.363103e-03 9.137957e-04 1.343874e+05 4.107046e+04 3.329715e+04 1.117611e+05", 
            "title": "Example output"
        }, 
        {
            "location": "/pipeline_script/", 
            "text": "Pipeline: a minimal example\n\n\nThis is a demonstration of the pipeline using Gaussian noise test data with randomly-selected signal added to the data (software injection).  \n\n\nStructure of the input data\n\n\nThe generic directory structure of the input data is\n\n\n001\n\u251c\u2500\u2500 grid.bin\n\u251c\u2500\u2500 H1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 DetSSB.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 grid.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 rDet.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 rSSB.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 starting_date\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 xdatc_001_1234.bin\n\u2514\u2500\u2500 L1\n    \u251c\u2500\u2500 DetSSB.bin\n    \u251c\u2500\u2500 grid.bin\n    \u251c\u2500\u2500 rDet.bin\n    \u251c\u2500\u2500 rSSB.bin\n    \u251c\u2500\u2500 starting_date\n    \u2514\u2500\u2500 xdatc_001_1234.bin\n\n\n\n\n\n(here for two LIGO detectors H1 and L1, and frame \n001\n). Test data frames \nnnn=001-008\n with pure Gaussian noise 2-day time segments with sampling time equal to 2s (\nxdatc_nnn_1234.bin\n) are \navailable here\n. \n\n\nIn principle, given the ephemerides (\nDetSSB.bin\n, \nrDet.bin\n and \nrSSB.bin\n) for each detector and frame \n001-008\n, one can create the grid matrices using the \ngridgen\n implementation (see the \ncode\n for details): \n\n\n# grid generation\n\n\ncd\n gridgen\nmake\n\nfor\n ifo in H1 L1\n;\n \ndo\n \nfor\n d in \n$(\nseq -f %03g \n1\n 8\n)\n;\n \ndo\n ./gridgen -m 0.5 -p dfg -d ../testdata/2d_0.25/\n${\nd\n}\n/\n${\nifo\n}\n/ -n 17\n;\n \ndone\n;\n \ndone\n\n\n\n# copying the H1 grid file one level up for the case of the network search \n\n\nfor\n d in \n$(\nseq -f %03g \n1\n 8\n)\n;\n \ndo\n cp -v ../testdata/2d_0.25/\n${\nd\n}\n/H1/grid.bin ../testdata/2d_0.25/\n${\nd\n}\n;\n \ndone\n\n\n\n\n\n\nTest Gaussian noise time series data were created as follows:  \n\n\n#!/bin/bash \n\n\n\nband\n=\n1234\n\n\n# Gaussian data generation\n\n\ncd\n ../search/network/scr-cpu\ngcc gauss-xdat.c -o gauss-xdat -lm -lgsl -lgslcblas\n\n# 86164: number of points in 2-day segment with 2s sampling time \n\n\nfor\n ifo in H1 L1\n;\n \ndo\n \nfor\n d in \n$(\nseq -f %03g \n1\n 8\n)\n;\n \ndo\n \necho\n \n$d\n \n$ifo\n;\n ./gauss-xdat \n86164\n \n1\n \n1\n ../../../testdata/2d_0.25/\n${\nd\n}\n/\n${\nifo\n}\n/xdatc_\n${\nd\n}\n_\n${\nband\n}\n.bin\n;\n \ndone\n;\n \ndone\n\n\n\n\n\n\nGiven the complete input data, this pipeline minimal example consists of \n\n\n\n\nAdding an artificial signal to the data (random parameters of the signal generated with \nsigen\n), \n\n\nPerforming a search around the injection for each time segment (\ngwsearch-cpu\n), \n\n\nLooking for coincidences between the candidate signals from different time frames (\ncoincidences\n), \n\n\nEstablishing the false alarm probability of the best coincidence (\nfap\n).   \n\n\n\n\n\n\nGenerating random parameters for the signal\n\n\nRandom parameters of the signal are chosen using the \nsigen\n and added to the data time series with the \nadd_signal()\n function in (\ninit\n). \n\n\n# Create random parameters of a signal signal\n\n\ncd\n search/network/src-cpu\nmake sigen\n\nband\n=\n1234\n;\n \ndt\n=\n2\n;\n \nnod\n=\n2\n;\n ./sigen -amp 4.e-2 -band \n$band\n -dt \n$dt\n -gsize \n10\n -reffr \n4\n -nod \n$nod\n 1\n sig1 \n\n\n\n\n\nSignal parameters used in this example:\n\n\n% cat sig1 \namp 4.000000e-02\n10\n4\n9.9791082090028898e-01\n-1.6533871297433800e-09\n-1.1821269273133420e-01\n1.9839903273071489e+00\n4.7717937494571394e-01\n7.5715524886052021e-01\n7.5154297884129850e-01\n-4.7938541489358644e-01\n\n\n\n\n\n\n\nAdding signal to the Gaussian data and searching for candidates\n\n\nband\n=\n1234\n;\n \ndt\n=\n2\n;\n \nnod\n=\n2\n;\n \nfor\n d in \n$(\nseq -f %03g \n1\n 8\n)\n;\n \ndo\n \n\n  \nLD_LIBRARY_PATH\n=\nlib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu \n\\\n\n  -data ../../../testdata/2d_0.25/ \n\\\n\n  -ident \n${\nd\n}\n \n\\\n\n  -band \n$band\n \n\\\n\n  -dt \n$dt\n \n\\ \n\n  -nod \n$nod\n \n\\ \n\n  -addsig sig1 \n\\ \n \n  -output . \n\\\n\n  -threshold 14.5 \n\\\n\n  --nocheckpoint \n\\ \n\n\n\ndone\n\n\n\n\n\n\nThis produces trigger files for each frame (size in bytes also listed): \n\n\n99320 triggers_001_1234_2.bin\n89960 triggers_002_1234_2.bin\n89880 triggers_003_1234_2.bin\n95360 triggers_004_1234_2.bin\n81600 triggers_005_1234_2.bin\n92200 triggers_006_1234_2.bin\n89040 triggers_007_1234_2.bin\n96320 triggers_008_1234_2.bin\n\n\n\n\n\nFirst 10 triggers from \ntriggers_001_1234_2.bin\n are \n\n\n3.05617018e+00 -3.42376198e-08 -7.68007347e-02 2.59248668e+00 5.06667333e+00 \n1.18243015e+00 -3.20762991e-08 -7.68007347e-02 2.59248668e+00 5.05528873e+00 \n1.08103361e-01 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.07085254e+00 \n1.90022435e+00 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.15191593e+00 \n1.90000217e+00 -2.55923371e-08 -7.68007347e-02 2.59248668e+00 5.42638039e+00 \n2.09224664e+00 -2.34310165e-08 -7.68007347e-02 2.59248668e+00 5.20879551e+00 \n2.38731576e+00 -2.12696958e-08 -7.68007347e-02 2.59248668e+00 5.31983396e+00 \n3.00543165e+00 -1.91083751e-08 -7.68007347e-02 2.59248668e+00 5.29454616e+00 \n7.49333983e-01 -1.26244131e-08 -7.68007347e-02 2.59248668e+00 5.08724856e+00 \n2.08710778e-01  3.43510887e-10 -7.68007347e-02 2.59248668e+00 5.17537018e+00 \n\n\n\n\n\n\n\nCoincidences among these trigger files\n\n\ncd\n ../../../coincidences/src\nmake\n\nband\n=\n1234\n;\n \ndt\n=\n2\n;\n \nnod\n=\n2\n;\n \nfpo\n=\n$(\necho\n \n$band\n \n$dt\n \n|\nawk \n{printf(\n%.6f\n, 10 + 0.96875*$1/(2.0*$2))}\n)\n;\n \nfor\n s in \n{\n0..1\n}{\n0..1\n}{\n0..1\n}{\n0..1\n}\n;\n \ndo\n \n\n  ./coincidences \n\\ \n\n  -data ../../search/network/src-cpu \n\\ \n\n  -output . \n\\ \n\n  -shift \n$s\n \n\\ \n\n  -scale \n4444\n \n\\ \n\n  -refr \n4\n \n\\ \n\n  -dt \n$dt\n \n\\ \n\n  -trigname \n${\nband\n}\n_2 \n\\ \n\n  -refloc ../../testdata/2d_0.25/004 \n\\ \n\n  -nod \n$nod\n \n\\ \n\n  -fpo \n$fpo\n \n\\ \n\n  -snrcutoff \n5\n \n\\ \n\n\n  \ndone\n 2\n summary\n\n\n# best shift (highest multiplicity with largest snr)\n\nsort -gk5 -gk10 summary \n|\n tail -1\n\n\n\n\n\nThe highest coincidence with the largest signal-to-noise ratio is  \n\n\n1234_2 1111 308.859375     8     5  9.95663703e-01 -1.10830358e-09 -1.12585347e-01 1.97463002e+00 1.246469e+01 5 2040 1987 1 2483 2419 4 2384 2193 3 2247 2137 8 2408 2363 2 2249 2172 6 2305 2220 7 2226 2191 6 2 8 3 5\n\n\n\n\n\n\n\nFalse alarm probability\n\n\nmake fap \n\n\nfap.sh \n(sort -gk5 -gk10 summary | tail -1) \n(echo \n$\nband\n 0.0) ../../testdata/2d_0.25/004\n\n\n\n\n\n\nresulting in \n\n\nNumber of days in time segments: 2\nInput data: /dev/fd/63\nGrid matrix data directory: ../../testdata/2d_0.25/004\nBand number: 1234 (veto fraction: 0.000000)\nThe reference frequency fpo: 308.859375\nThe data sampling time dt: 2.000000\nFAP threshold: 1.000000\nCell size: 4\n1234 3.088594e+02 3.091094e+02 7.665713e-08 5 17682 9.956637e-01 -1.108304e-09 -1.125853e-01 1.974630e+00 1.246469e+01 2\n\n\n\n\n\nThe false alarm probability in this case is \n7.665713e-08\n. It's low enough to be an interesting outlier for a \nfollowup\n procedure.", 
            "title": "Pipeline: a minimal example"
        }, 
        {
            "location": "/pipeline_script/#pipeline-a-minimal-example", 
            "text": "This is a demonstration of the pipeline using Gaussian noise test data with randomly-selected signal added to the data (software injection).", 
            "title": "Pipeline: a minimal example"
        }, 
        {
            "location": "/pipeline_script/#structure-of-the-input-data", 
            "text": "The generic directory structure of the input data is  001\n\u251c\u2500\u2500 grid.bin\n\u251c\u2500\u2500 H1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 DetSSB.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 grid.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 rDet.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 rSSB.bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 starting_date\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 xdatc_001_1234.bin\n\u2514\u2500\u2500 L1\n    \u251c\u2500\u2500 DetSSB.bin\n    \u251c\u2500\u2500 grid.bin\n    \u251c\u2500\u2500 rDet.bin\n    \u251c\u2500\u2500 rSSB.bin\n    \u251c\u2500\u2500 starting_date\n    \u2514\u2500\u2500 xdatc_001_1234.bin  (here for two LIGO detectors H1 and L1, and frame  001 ). Test data frames  nnn=001-008  with pure Gaussian noise 2-day time segments with sampling time equal to 2s ( xdatc_nnn_1234.bin ) are  available here .   In principle, given the ephemerides ( DetSSB.bin ,  rDet.bin  and  rSSB.bin ) for each detector and frame  001-008 , one can create the grid matrices using the  gridgen  implementation (see the  code  for details):   # grid generation  cd  gridgen\nmake for  ifo in H1 L1 ;   do   for  d in  $( seq -f %03g  1  8 ) ;   do  ./gridgen -m 0.5 -p dfg -d ../testdata/2d_0.25/ ${ d } / ${ ifo } / -n 17 ;   done ;   done  # copying the H1 grid file one level up for the case of the network search   for  d in  $( seq -f %03g  1  8 ) ;   do  cp -v ../testdata/2d_0.25/ ${ d } /H1/grid.bin ../testdata/2d_0.25/ ${ d } ;   done   Test Gaussian noise time series data were created as follows:    #!/bin/bash   band = 1234 # Gaussian data generation  cd  ../search/network/scr-cpu\ngcc gauss-xdat.c -o gauss-xdat -lm -lgsl -lgslcblas # 86164: number of points in 2-day segment with 2s sampling time   for  ifo in H1 L1 ;   do   for  d in  $( seq -f %03g  1  8 ) ;   do   echo   $d   $ifo ;  ./gauss-xdat  86164   1   1  ../../../testdata/2d_0.25/ ${ d } / ${ ifo } /xdatc_ ${ d } _ ${ band } .bin ;   done ;   done   Given the complete input data, this pipeline minimal example consists of    Adding an artificial signal to the data (random parameters of the signal generated with  sigen ),   Performing a search around the injection for each time segment ( gwsearch-cpu ),   Looking for coincidences between the candidate signals from different time frames ( coincidences ),   Establishing the false alarm probability of the best coincidence ( fap ).", 
            "title": "Structure of the input data"
        }, 
        {
            "location": "/pipeline_script/#generating-random-parameters-for-the-signal", 
            "text": "Random parameters of the signal are chosen using the  sigen  and added to the data time series with the  add_signal()  function in ( init ).   # Create random parameters of a signal signal  cd  search/network/src-cpu\nmake sigen band = 1234 ;   dt = 2 ;   nod = 2 ;  ./sigen -amp 4.e-2 -band  $band  -dt  $dt  -gsize  10  -reffr  4  -nod  $nod  1  sig1   Signal parameters used in this example:  % cat sig1 \namp 4.000000e-02\n10\n4\n9.9791082090028898e-01\n-1.6533871297433800e-09\n-1.1821269273133420e-01\n1.9839903273071489e+00\n4.7717937494571394e-01\n7.5715524886052021e-01\n7.5154297884129850e-01\n-4.7938541489358644e-01", 
            "title": "Generating random parameters for the signal"
        }, 
        {
            "location": "/pipeline_script/#adding-signal-to-the-gaussian-data-and-searching-for-candidates", 
            "text": "band = 1234 ;   dt = 2 ;   nod = 2 ;   for  d in  $( seq -f %03g  1  8 ) ;   do  \n\n   LD_LIBRARY_PATH = lib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu  \\ \n  -data ../../../testdata/2d_0.25/  \\ \n  -ident  ${ d }   \\ \n  -band  $band   \\ \n  -dt  $dt   \\  \n  -nod  $nod   \\  \n  -addsig sig1  \\   \n  -output .  \\ \n  -threshold 14.5  \\ \n  --nocheckpoint  \\   done   This produces trigger files for each frame (size in bytes also listed):   99320 triggers_001_1234_2.bin\n89960 triggers_002_1234_2.bin\n89880 triggers_003_1234_2.bin\n95360 triggers_004_1234_2.bin\n81600 triggers_005_1234_2.bin\n92200 triggers_006_1234_2.bin\n89040 triggers_007_1234_2.bin\n96320 triggers_008_1234_2.bin  First 10 triggers from  triggers_001_1234_2.bin  are   3.05617018e+00 -3.42376198e-08 -7.68007347e-02 2.59248668e+00 5.06667333e+00 \n1.18243015e+00 -3.20762991e-08 -7.68007347e-02 2.59248668e+00 5.05528873e+00 \n1.08103361e-01 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.07085254e+00 \n1.90022435e+00 -2.77536578e-08 -7.68007347e-02 2.59248668e+00 5.15191593e+00 \n1.90000217e+00 -2.55923371e-08 -7.68007347e-02 2.59248668e+00 5.42638039e+00 \n2.09224664e+00 -2.34310165e-08 -7.68007347e-02 2.59248668e+00 5.20879551e+00 \n2.38731576e+00 -2.12696958e-08 -7.68007347e-02 2.59248668e+00 5.31983396e+00 \n3.00543165e+00 -1.91083751e-08 -7.68007347e-02 2.59248668e+00 5.29454616e+00 \n7.49333983e-01 -1.26244131e-08 -7.68007347e-02 2.59248668e+00 5.08724856e+00 \n2.08710778e-01  3.43510887e-10 -7.68007347e-02 2.59248668e+00 5.17537018e+00", 
            "title": "Adding signal to the Gaussian data and searching for candidates"
        }, 
        {
            "location": "/pipeline_script/#coincidences-among-these-trigger-files", 
            "text": "cd  ../../../coincidences/src\nmake band = 1234 ;   dt = 2 ;   nod = 2 ;   fpo = $( echo   $band   $dt   | awk  {printf( %.6f , 10 + 0.96875*$1/(2.0*$2))} ) ;   for  s in  { 0..1 }{ 0..1 }{ 0..1 }{ 0..1 } ;   do  \n\n  ./coincidences  \\  \n  -data ../../search/network/src-cpu  \\  \n  -output .  \\  \n  -shift  $s   \\  \n  -scale  4444   \\  \n  -refr  4   \\  \n  -dt  $dt   \\  \n  -trigname  ${ band } _2  \\  \n  -refloc ../../testdata/2d_0.25/004  \\  \n  -nod  $nod   \\  \n  -fpo  $fpo   \\  \n  -snrcutoff  5   \\  \n\n   done  2  summary # best shift (highest multiplicity with largest snr) \nsort -gk5 -gk10 summary  |  tail -1  The highest coincidence with the largest signal-to-noise ratio is    1234_2 1111 308.859375     8     5  9.95663703e-01 -1.10830358e-09 -1.12585347e-01 1.97463002e+00 1.246469e+01 5 2040 1987 1 2483 2419 4 2384 2193 3 2247 2137 8 2408 2363 2 2249 2172 6 2305 2220 7 2226 2191 6 2 8 3 5", 
            "title": "Coincidences among these trigger files"
        }, 
        {
            "location": "/pipeline_script/#false-alarm-probability", 
            "text": "make fap   fap.sh  (sort -gk5 -gk10 summary | tail -1)  (echo  $ band  0.0) ../../testdata/2d_0.25/004   resulting in   Number of days in time segments: 2\nInput data: /dev/fd/63\nGrid matrix data directory: ../../testdata/2d_0.25/004\nBand number: 1234 (veto fraction: 0.000000)\nThe reference frequency fpo: 308.859375\nThe data sampling time dt: 2.000000\nFAP threshold: 1.000000\nCell size: 4\n1234 3.088594e+02 3.091094e+02 7.665713e-08 5 17682 9.956637e-01 -1.108304e-09 -1.125853e-01 1.974630e+00 1.246469e+01 2  The false alarm probability in this case is  7.665713e-08 . It's low enough to be an interesting outlier for a  followup  procedure.", 
            "title": "False alarm probability"
        }, 
        {
            "location": "/articles/", 
            "text": "List of documents and publications\n\n\nMethods\n\n\n\n\nData analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. V. A narrow-band all-sky search\n \n(arXiv)\n\n\nBanks of templates for all-sky narrow-band searches of gravitational waves from spinning neutron stars\n \n(arXiv)\n \n\n\n\n\nVirgo VSR1 data\n\n\n\n\nImplementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data\n \n(arXiv)\n\n\n\n\nMock Data Challenge using the LIGO S6 data\n\n\n\n\nA comparison of methods for the detection of gravitational waves from unknown neutron stars\n \n(arXiv)\n \n\n\n\n\nLIGO O1\n\n\n\n\nFirst search for gravitational waves from known pulsars with Advanced LIGO\n \n\n\nAll-sky Search for Periodic Gravitational Waves in the O1 LIGO Data\n\n\n\n\nResonant bar detectors\n\n\n\n\nAll-sky search of NAUTILUS data\n \n(arXiv)\n\n\nAll-sky upper limit for gravitational radiation from spinning neutron stars\n \n(arXiv)\n\n\n\n\nMonographs\n\n\n\n\nGravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case\n\n\nAnalysis of Gravitational-Wave Data", 
            "title": "Documents and publications"
        }, 
        {
            "location": "/articles/#list-of-documents-and-publications", 
            "text": "", 
            "title": "List of documents and publications"
        }, 
        {
            "location": "/articles/#methods", 
            "text": "Data analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. V. A narrow-band all-sky search   (arXiv)  Banks of templates for all-sky narrow-band searches of gravitational waves from spinning neutron stars   (arXiv)", 
            "title": "Methods"
        }, 
        {
            "location": "/articles/#virgo-vsr1-data", 
            "text": "Implementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data   (arXiv)", 
            "title": "Virgo VSR1 data"
        }, 
        {
            "location": "/articles/#mock-data-challenge-using-the-ligo-s6-data", 
            "text": "A comparison of methods for the detection of gravitational waves from unknown neutron stars   (arXiv)", 
            "title": "Mock Data Challenge using the LIGO S6 data"
        }, 
        {
            "location": "/articles/#ligo-o1", 
            "text": "First search for gravitational waves from known pulsars with Advanced LIGO    All-sky Search for Periodic Gravitational Waves in the O1 LIGO Data", 
            "title": "LIGO O1"
        }, 
        {
            "location": "/articles/#resonant-bar-detectors", 
            "text": "All-sky search of NAUTILUS data   (arXiv)  All-sky upper limit for gravitational radiation from spinning neutron stars   (arXiv)", 
            "title": "Resonant bar detectors"
        }, 
        {
            "location": "/articles/#monographs", 
            "text": "Gravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case  Analysis of Gravitational-Wave Data", 
            "title": "Monographs"
        }
    ]
}